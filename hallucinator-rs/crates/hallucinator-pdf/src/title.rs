use once_cell::sync::Lazy;
use regex::Regex;
use std::collections::HashSet;

use crate::config::PdfParsingConfig;
use crate::text_processing::fix_hyphenation;

/// Abbreviations that should NEVER be sentence boundaries (mid-title abbreviations).
static MID_SENTENCE_ABBREVIATIONS: Lazy<HashSet<&'static str>> = Lazy::new(|| {
    [
        "vs", "eg", "ie", "cf", "fig", "figs", "eq", "eqs", "sec", "ch", "pt", "no",
    ]
    .into_iter()
    .collect()
});

/// Extract title from a reference string.
///
/// Handles multiple formats:
/// - IEEE/USENIX: Authors, "Title," in Venue, Year
/// - LNCS/Springer: Authors, I.: Title. In: Venue
/// - ACM: Authors. Year. Title. In Venue
/// - Springer/Nature/Harvard: Authors (Year) Title. Journal
/// - AAAI: Authors. Title. Venue
/// - Journal style: Authors. Title. Journal Name, Vol(Issue)
/// - ALL CAPS authors: SURNAME, F. Title here.
///
/// Returns `(title, from_quotes)` where `from_quotes` indicates if the title was in quotes.
pub fn extract_title_from_reference(ref_text: &str) -> (String, bool) {
    extract_title_from_reference_with_config(ref_text, &PdfParsingConfig::default())
}

/// Config-aware version of [`extract_title_from_reference`].
pub(crate) fn extract_title_from_reference_with_config(
    ref_text: &str,
    config: &PdfParsingConfig,
) -> (String, bool) {
    // Normalize whitespace and fix hyphenation
    let ref_text = fix_hyphenation(ref_text);
    static WS_RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"\s+").unwrap());
    let ref_text = WS_RE.replace_all(&ref_text, " ");
    let ref_text = ref_text.trim();

    // Strip reference number prefixes: [N] or N.
    static REF_NUM_BRACKET: Lazy<Regex> = Lazy::new(|| Regex::new(r"^\[\d+\]\s*").unwrap());
    static REF_NUM_DOT: Lazy<Regex> = Lazy::new(|| Regex::new(r"^\d+\.\s*").unwrap());
    let ref_text = REF_NUM_BRACKET.replace(ref_text, "");
    let ref_text = REF_NUM_DOT.replace(&ref_text, "");
    let ref_text = ref_text.trim_start_matches(['.', ' ']);

    // === Format 1: IEEE/USENIX - Quoted titles ===
    if let Some(result) = try_quoted_title_with_config(ref_text, config) {
        return result;
    }

    // === Format 1a: Bracket citation - "[ACGH20] Authors. Title. In Venue" ===
    if let Some(result) = try_bracket_code(ref_text) {
        return result;
    }

    // === Format 1b: LNCS/Springer - "Authors, I.: Title. In: Venue" ===
    if let Some(result) = try_lncs(ref_text) {
        return result;
    }

    // === Format 1c: Organization/Documentation - "Organization: Title (Year)" ===
    if let Some(result) = try_org_doc(ref_text) {
        return result;
    }

    // === Format 2: Author names with particles (von, van der, etc.) ===
    // Must run before venue marker and year-based formats, since those
    // mis-split at "P. von Styp-Rekowsky" treating "P." as sentence end
    if let Some(result) = try_author_particles(ref_text) {
        return result;
    }

    // === Format 2b: Book citation - "Author and Author, Title. Publisher, Year." ===
    if let Some(result) = try_book_citation(ref_text) {
        return result;
    }

    // === Format 3a: Springer/Nature/Harvard - "Authors (Year) Title" ===
    if let Some(result) = try_springer_year(ref_text) {
        return result;
    }

    // === Format 3b: arXiv preprint - "Authors. Title. Year. arXiv: ID" ===
    // Title comes BEFORE the year in this format (must run before try_acm_year)
    if let Some(result) = try_arxiv_preprint(ref_text) {
        return result;
    }

    // === Format 3c: ACM - "Authors. Year. Title. In Venue" ===
    if let Some(result) = try_acm_year(ref_text) {
        return result;
    }

    // === Format 4: USENIX/ICML/NeurIPS/Elsevier - "Authors. Title. In Venue" ===
    if let Some(result) = try_venue_marker(ref_text) {
        return result;
    }

    // === Format 5: Journal style ===
    if let Some(result) = try_journal(ref_text) {
        return result;
    }

    // === Format 5b: Elsevier journal ===
    if let Some(result) = try_elsevier_journal(ref_text) {
        return result;
    }

    // === Format 6a: Chinese ALL CAPS authors (SURNAME I, SURNAME I, et al. Title) ===
    if let Some(result) = try_chinese_allcaps(ref_text) {
        return result;
    }

    // === Format 6b: Western ALL CAPS authors (SURNAME, F. Title) ===
    if let Some(result) = try_all_caps_authors(ref_text) {
        return result;
    }

    // === Format 7: Direct "Title. In Venue" fallback ===
    if let Some(result) = try_direct_in_venue(ref_text) {
        return result;
    }

    // === Fallback: second sentence ===
    if let Some(result) = try_fallback_sentence(ref_text) {
        return result;
    }

    (String::new(), false)
}

/// Clean extracted title by removing trailing venue/metadata.
pub fn clean_title(title: &str, from_quotes: bool) -> String {
    clean_title_with_config(title, from_quotes, &PdfParsingConfig::default())
}

/// Config-aware version of [`clean_title`].
pub(crate) fn clean_title_with_config(
    title: &str,
    from_quotes: bool,
    config: &PdfParsingConfig,
) -> String {
    if title.is_empty() {
        return String::new();
    }

    let mut title = fix_hyphenation(title);

    // Strip leading year from ACM-style titles ("2017. Title" -> "Title")
    // Must run BEFORE truncate_at_sentence_end to avoid truncating at year period
    static LEADING_YEAR: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"^(?:19|20)\d{2}[a-z]?\.\s+").unwrap());
    if LEADING_YEAR.is_match(&title) {
        title = LEADING_YEAR.replace(&title, "").to_string();
    }

    // For non-quoted titles, truncate at first sentence-ending period
    if !from_quotes {
        title = truncate_at_sentence_end(&title);
    }

    // Handle "? In" and "? In:" patterns
    static IN_VENUE_RE: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"\?\s*[Ii]n:?\s+(?:[A-Z]|[12]\d{3}\s)").unwrap());
    if let Some(m) = IN_VENUE_RE.find(&title) {
        // Keep the question mark
        let qmark_pos = title[..m.end()].rfind('?').unwrap();
        title = title[..=qmark_pos].to_string();
    }

    // Handle "? JournalName, vol(issue)" — journal name bleeding after question mark
    static QMARK_JOURNAL_RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(r"[?!]\s+[A-Z][a-zA-Z\s&+\u{00AE}\u{2013}\u{2014}\-]+,\s*(?:vol\.?\s*)?\d+")
            .unwrap()
    });
    if let Some(m) = QMARK_JOURNAL_RE.find(&title) {
        let punct_pos = title[..m.end()].rfind(['?', '!']).unwrap();
        title = title[..=punct_pos].to_string();
    }

    // Handle "? Automatica 34(" or "? IEEE Trans... 53(" — journal + volume with parens
    static QMARK_JOURNAL_VOL_RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(
            r"[?!]\s+(?:IEEE\s+Trans[a-z.]*|ACM\s+Trans[a-z.]*|Automatica|J\.\s*[A-Z][a-z]+|[A-Z][a-z]+\.?\s+[A-Z][a-z]+\.?)\s+\d+\s*[(\[]",
        )
        .unwrap()
    });
    if let Some(m) = QMARK_JOURNAL_VOL_RE.find(&title) {
        let punct_pos = title[..m.end()].rfind(['?', '!']).unwrap();
        title = title[..=punct_pos].to_string();
    }

    // Handle "? IEEE Trans. Aut. Contr. 53" — abbreviated journal + volume, no parens
    static QMARK_ABBREV_JOURNAL_RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(r"[?!]\s+(?:IEEE|ACM|SIAM)\s+Trans[a-z.]*(?:\s+[A-Z][a-z]+\.?)+\s+\d+").unwrap()
    });
    if let Some(m) = QMARK_ABBREV_JOURNAL_RE.find(&title) {
        let punct_pos = title[..m.end()].rfind(['?', '!']).unwrap();
        title = title[..=punct_pos].to_string();
    }

    // FIX 1 (NeurIPS): Broader venue/conference names after ?/! punctuation
    static VENUE_AFTER_PUNCTUATION_RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(
            r"[?!]\s+(?:International|Proceedings|Conference|Workshop|Symposium|Association|The\s+\d{4}\s+Conference|Nations|Annual|IEEE|ACM|USENIX|AAAI|NeurIPS|ICML|ICLR|CVPR|ICCV|ECCV|ACL|EMNLP|NAACL)",
        )
        .unwrap()
    });
    if let Some(m) = VENUE_AFTER_PUNCTUATION_RE.find(&title) {
        let punct_pos = title[..m.end()].rfind(['?', '!']).unwrap();
        title = title[..=punct_pos].to_string();
    }

    // Handle "? ACRONYM, year" — ALL-CAPS venue acronym + comma + 4-digit year after ?/!
    // Catches venues like PACMPL, JMLR, VLDB, etc. that aren't in the explicit list above
    static QMARK_ACRONYM_VENUE_RE: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"[?!]\s+[A-Z]{3,}[a-z]?\s*,\s*(?:19|20)\d{2}").unwrap());
    if let Some(m) = QMARK_ACRONYM_VENUE_RE.find(&title) {
        let punct_pos = title[..m.end()].rfind(['?', '!']).unwrap();
        title = title[..=punct_pos].to_string();
    }

    // Handle multi-word venues after ?/! like "! IACR Cryptology ePrint Archive, 2021"
    static QMARK_MULTIWORD_VENUE_RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(r"[?!]\s+(?:IACR|Cryptology\s+ePrint|ePrint\s+Archive)\b.*$").unwrap()
    });
    if let Some(m) = QMARK_MULTIWORD_VENUE_RE.find(&title) {
        let punct_pos = title[..m.end()].rfind(['?', '!']).unwrap();
        title = title[..=punct_pos].to_string();
    }

    // Handle "? The American Economic Review" — full journal name starting with "The" after ?/!
    static QMARK_THE_JOURNAL_RE: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"[?!]\s+The\s+[A-Z][a-zA-Z]+(?:\s+[A-Z][a-zA-Z]+)+").unwrap());
    if let Some(m) = QMARK_THE_JOURNAL_RE.find(&title) {
        let punct_pos = title[..m.end()].rfind(['?', '!']).unwrap();
        title = title[..=punct_pos].to_string();
    }

    // Remove editor lists: ". In Name, Name, and Name, editors, Venue"
    static EDITOR_LIST_RE: Lazy<Regex> = Lazy::new(|| {
        let name = r"[A-Za-z\u{00C0}-\u{024F}]+(?:\s+[A-Z]\.)*(?:\s+[A-Za-z\u{00C0}-\u{024F}]+)?";
        Regex::new(&format!(
            r"\.\s*In\s+{n}(?:,\s*{n})*(?:,?\s*and\s+{n})?,\s*editors?,",
            n = name
        ))
        .unwrap()
    });
    if let Some(m) = EDITOR_LIST_RE.find(&title) {
        title = title[..m.start()].to_string();
    }

    // Apply cutoff patterns to remove trailing venue/metadata
    title = apply_cutoff_patterns_with_config(&title, config);

    // Remove trailing ", MONTH YEAR" patterns like ", 5 2019" or ", 3 2023"
    static TRAILING_MONTH_YEAR_RE: Lazy<Regex> =
        Lazy::new(|| Regex::new(r",\s+\d{1,2}\s+(?:19|20)\d{2}\s*$").unwrap());
    if let Some(m) = TRAILING_MONTH_YEAR_RE.find(&title) {
        title = title[..m.start()].to_string();
    }

    // FIX 2 (NeurIPS): Reject venue-only titles
    if is_venue_only(&title) {
        return String::new();
    }

    // FIX 3 (NeurIPS): Reject author initials lists ("AL, Name Name, Name Name")
    static AUTHOR_INITIALS_LIST_RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(r"^[A-Z]{1,3},\s+[A-Z][a-z]+\s+[A-Z][a-z]+,\s+[A-Z][a-z]+\s+[A-Z][a-z]+")
            .unwrap()
    });
    if AUTHOR_INITIALS_LIST_RE.is_match(&title) {
        return String::new();
    }

    // FIX 3a (IEEE): Reject IEEE ALL CAPS author lists
    if is_likely_author_list(&title) {
        return String::new();
    }

    // FIX 3b (NeurIPS/ML): Reject "I. Surname, I. Surname, and I. Surname" author lists
    static ML_AUTHOR_LIST_RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(
            r"^[A-Z]\.(?:\s*[A-Z]\.)?\s+[A-Z][a-z]+,\s+[A-Z]\.(?:\s*[A-Z]\.)?\s+[A-Z][a-z]+,\s+and\s+[A-Z]\.",
        )
        .unwrap()
    });
    if ML_AUTHOR_LIST_RE.is_match(&title) {
        return String::new();
    }

    // FIX 4 (NeurIPS): Reject non-reference content (checklists, acknowledgments)
    static NON_REFERENCE_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            Regex::new(r"(?i)^[•\-]\s+(?:The answer|Released models|If you are using)").unwrap(),
            Regex::new(r"(?i)^We gratefully acknowledge").unwrap(),
        ]
    });
    if NON_REFERENCE_PATTERNS.iter().any(|re| re.is_match(&title)) {
        return String::new();
    }

    // FIX 4b: Reject code snippets (assembly, inline code)
    static CODE_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            // Assembly: "rep; movsb;" or "mov eax, ebx;"
            Regex::new(r"(?i)^(?:rep|mov|push|pop|call|ret|jmp|asm)\s*;").unwrap(),
            Regex::new(r"(?i)\basm\s+volatile\s*\(").unwrap(),
            // GCC inline asm output/input constraints: "=S", "=D", etc.
            Regex::new(r#""=[A-Z]"\s*\("#).unwrap(),
            // Multiple semicolons with short tokens (code-like)
            Regex::new(r";\s*[a-z]{2,6}\s*;").unwrap(),
            // Assembly instructions: "mov eax, ebx" or "push ecx" patterns
            Regex::new(
                r"(?i)\b(?:mov|push|pop|call|ret|jmp|lea|add|sub|xor|and|or)\s+[a-z]{2,3}[,;]",
            )
            .unwrap(),
        ]
    });
    if CODE_PATTERNS.iter().any(|re| re.is_match(&title)) {
        return String::new();
    }

    // FIX 4c: Reject "arXiv preprint" as a title (extraction failed)
    static ARXIV_ONLY: Lazy<Regex> = Lazy::new(|| Regex::new(r"(?i)^arXiv\s+preprint\b").unwrap());
    if ARXIV_ONLY.is_match(&title) {
        return String::new();
    }

    // FIX 4d: Reject arXiv IDs as titles (e.g., "arXiv: 2304.06341 [cs.CR]")
    static ARXIV_ID_ONLY: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"(?i)^arXiv[:\s]+\d+\.\d+").unwrap());
    if ARXIV_ID_ONLY.is_match(&title) {
        return String::new();
    }

    // FIX 4e: Reject DOI URLs as titles
    static DOI_URL_ONLY: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"(?i)^https?://(?:dx\.)?doi\.org/").unwrap());
    if DOI_URL_ONLY.is_match(&title) {
        return String::new();
    }

    // FIX 4f: Reject ACM "[n. d.]" / "[n.d.]" marker extracted as title
    static NO_DATE_MARKER: Lazy<Regex> = Lazy::new(|| Regex::new(r"(?i)^\[n\.?\s*d\.?\]").unwrap());
    if NO_DATE_MARKER.is_match(&title) {
        return String::new();
    }

    // FIX 5 (NeurIPS): Reject titles exceeding maximum reasonable length
    const MAX_TITLE_LENGTH: usize = 300;
    if title.len() > MAX_TITLE_LENGTH {
        return String::new();
    }

    title = title.trim().to_string();
    static TRAILING_PUNCT: Lazy<Regex> = Lazy::new(|| Regex::new(r"[.,;:]+$").unwrap());
    title = TRAILING_PUNCT.replace(&title, "").to_string();

    title.trim().to_string()
}

// ───────────────── Format-specific extractors ─────────────────

fn try_quoted_title_with_config(
    ref_text: &str,
    config: &PdfParsingConfig,
) -> Option<(String, bool)> {
    // First, try greedy IEEE pattern for titles with nested/inner quotes.
    // Matches from first " to last ," (IEEE convention: title ends with comma inside quotes)
    // e.g. "Autoadmin "what-if" index analysis utility,"
    static GREEDY_IEEE_RE: Lazy<Regex> = Lazy::new(|| Regex::new(r#""(.+),"\s"#).unwrap());
    if let Some(caps) = GREEDY_IEEE_RE.captures(ref_text) {
        let title = caps.get(1).unwrap().as_str().trim();
        if title.split_whitespace().count() >= 2 {
            return Some((format!("{},", title), true));
        }
    }

    static DEFAULT_QUOTE_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            // Smart quotes (any combo of \u201c, \u201d, \u201c)
            Regex::new(r#"[\u{201c}\u{201d}"]([^\u{201c}\u{201d}"]+)[\u{201c}\u{201d}"]"#).unwrap(),
            // Regular quotes
            Regex::new(r#""([^"]+)""#).unwrap(),
            // Smart single quotes (Harvard/APA style): \u2018...\u2019
            Regex::new(r"[\u{2018}]([^\u{2018}\u{2019}]{10,})[\u{2019}]").unwrap(),
            // Plain single quotes (Harvard/APA style): require ') ' or similar delimiter
            // to avoid matching possessive apostrophes
            Regex::new(r"(?:^|[\s(])'([^']{10,})'(?:\s*[,.]|\s*$)").unwrap(),
        ]
    });

    let resolved = config.quote_patterns.resolve(&DEFAULT_QUOTE_PATTERNS);

    for re in resolved.iter() {
        if let Some(caps) = re.captures(ref_text) {
            let quoted_part = caps.get(1).unwrap().as_str().trim();
            let before_quote = ref_text[..caps.get(0).unwrap().start()].trim();
            let after_quote = ref_text[caps.get(0).unwrap().end()..].trim();

            // Check for "middle quote" pattern: significant text BEFORE the quote
            // that looks like part of a title (not just author names).
            // e.g., "A Study of "Something" in Systems" - skip, let other extractors handle
            if has_title_text_before_quote(before_quote) {
                continue;
            }

            // IEEE: comma inside quotes means title is complete
            // Accept 2+ words for quoted titles (quotes are a strong indicator)
            if quoted_part.ends_with(',') {
                if quoted_part.split_whitespace().count() >= 2 {
                    return Some((quoted_part.to_string(), true));
                }
                continue;
            }

            // Check for subtitle after the quote — but only if quoted part is long enough
            // (>= 2 words). Short inner quotes like "Proof-Carrying" are likely embedded
            // in a longer title, not actual title delimiters.
            if !after_quote.is_empty() && quoted_part.split_whitespace().count() >= 2 {
                let subtitle_text = if after_quote.starts_with(':') || after_quote.starts_with('-')
                {
                    Some(after_quote[1..].trim())
                } else if after_quote.chars().next().is_some_and(|c| c.is_uppercase()) {
                    Some(after_quote)
                } else {
                    // Also handle lowercase continuation - truncate at venue markers
                    // e.g., "Title" examining something. In Conf → "Title examining something"
                    let end = find_subtitle_end(after_quote);
                    if end > 0 {
                        Some(&after_quote[..end])
                    } else {
                        None
                    }
                };

                if let Some(sub) = subtitle_text {
                    let subtitle_end = find_subtitle_end(sub);
                    let subtitle = sub[..subtitle_end].trim();
                    static TRAIL: Lazy<Regex> = Lazy::new(|| Regex::new(r"[.,;:]+$").unwrap());
                    let subtitle = TRAIL.replace(subtitle, "");
                    if subtitle.split_whitespace().count() >= 2 {
                        return Some((format!("{}: {}", quoted_part, subtitle), true));
                    }
                }
            }

            // No subtitle — use quoted part if long enough
            // Accept 2+ words for quoted titles (quotes are a strong indicator)
            if quoted_part.split_whitespace().count() >= 2 {
                return Some((quoted_part.to_string(), true));
            }
        }
    }
    None
}

/// Check if text before a quote contains significant title content (not just author names).
/// Returns true if this looks like a "middle quote" pattern where the quote is embedded
/// in a larger title, e.g., "A Study of "Something" in Systems" or "Comments on "X"".
fn has_title_text_before_quote(before: &str) -> bool {
    let before = before.trim();
    if before.is_empty() {
        return false;
    }

    // Look for the title portion after the last sentence boundary (year or period)
    // e.g., "Author. 1996. Comments on " → extract "Comments on"
    // e.g., "Author. A Study of " → extract "A Study of"
    static TITLE_START: Lazy<Regex> = Lazy::new(|| {
        // Match year followed by period/space, or just a period followed by space
        Regex::new(r"(?:\d{4}[.\s]+|\.\s+)([A-Z].*)$").unwrap()
    });

    let title_portion = if let Some(caps) = TITLE_START.captures(before) {
        caps.get(1).unwrap().as_str().trim()
    } else {
        before
    };

    if title_portion.is_empty() {
        return false;
    }

    // Check if the title portion ends with a preposition, article, or conjunction,
    // indicating it continues into the quoted text
    // e.g., "Comments on", "A Study of", "Finding a", "Good proctor or"
    static CONTINUES_INTO_QUOTE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(r"(?i)\b(of|on|in|for|with|to|a|an|the|about|from|into|through|toward|towards|called|titled|named|entitled|or|and|vs|versus)\s*$").unwrap()
    });

    if CONTINUES_INTO_QUOTE.is_match(title_portion) {
        return true;
    }

    // Also check for capitalized title-like patterns that don't end in prepositions
    // but clearly look like title content (multiple words starting with caps)
    // e.g., "A Comprehensive Study"
    let words: Vec<&str> = title_portion.split_whitespace().collect();
    if words.len() >= 2 {
        // Check if it looks like a title (has articles/prepositions typical of titles)
        // Match title words followed by space and another word (to exclude initials like "A.")
        // e.g., "A Study" matches, but "A.," does not
        static TITLE_WORDS: Lazy<Regex> =
            Lazy::new(|| Regex::new(r"(?i)\b(a|an|the|of|in|on|for|with|to)\s+[a-z]").unwrap());
        if TITLE_WORDS.is_match(title_portion) {
            return true;
        }
    }

    false
}

fn find_subtitle_end(text: &str) -> usize {
    static END_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        let j = r"[a-zA-Z&+\u{00AE}\u{2013}\u{2014}\-]"; // journal name chars (no \s)
        vec![
            Regex::new(r"\.\s*[Ii]n\s+").unwrap(),
            Regex::new(r"\.\s*(?:Proc|IEEE|ACM|USENIX|NDSS|CCS|AAAI|WWW|CHI|arXiv)").unwrap(),
            Regex::new(r",\s*[Ii]n\s+").unwrap(),
            Regex::new(r"\.\s*\((?:19|20)\d{2}\)").unwrap(),
            Regex::new(r"[,.]\s*(?:19|20)\d{2}").unwrap(),
            Regex::new(r"\s+(?:19|20)\d{2}\.").unwrap(),
            Regex::new(r"[.,]\s+[A-Z][a-z]+\s+\d+[,\s]").unwrap(),
            Regex::new(&format!(r"\.\s*[A-Z](?:{}|\s)+,\s*\d+\s*[,(:]", j)).unwrap(),
        ]
    });

    let mut end = text.len();
    for re in END_PATTERNS.iter() {
        if let Some(m) = re.find(text) {
            end = end.min(m.start());
        }
    }
    end
}

fn try_lncs(ref_text: &str) -> Option<(String, bool)> {
    // Enhanced Springer/LNCS format: "Author, I., Author, I.: Title. In: Venue"
    // Also handles multi-initial patterns like "B.S.:", "C.P.:", "L.:"
    // Also handles "et al.:" pattern (case-insensitive)
    static RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(r"(?:(?:,\s*)?[A-Z](?:\.[A-Z])*\.\s*:\s*|(?i)\bet\s+al\.\s*:\s*)(.+)").unwrap()
    });

    let caps = RE.captures(ref_text)?;
    let after_colon = caps.get(1).unwrap().as_str().trim();

    let title_end = find_title_end_lncs(after_colon);
    let title = after_colon[..title_end].trim();
    static TRAIL: Lazy<Regex> = Lazy::new(|| Regex::new(r"[.,;:]+\s*$").unwrap());
    let title = TRAIL.replace(title, "");

    // Reject if what we extracted looks like journal metadata, not a title
    if is_journal_metadata(&title) {
        return None;
    }

    if title.split_whitespace().count() >= 2 {
        Some((title.to_string(), false))
    } else {
        None
    }
}

fn find_title_end_lncs(text: &str) -> usize {
    static PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            // Journal + volume(issue): ". Journal 13(6),"
            Regex::new(r"\.\s+[A-Z][A-Za-z\s&\-]+\s+\d+\s*\(\d+\)\s*[,:]").unwrap(),
            // Journal + volume, pages: ". Journal 13, 456" or ": 456"
            Regex::new(r"\.\s+[A-Z][A-Za-z\s&\-]+\s+\d+\s*[,:]\s*\d+").unwrap(),
            // In/In: venue markers
            Regex::new(r"\.\s*[Ii]n:\s+").unwrap(),
            Regex::new(r"\.\s*[Ii]n\s+[A-Z]").unwrap(),
            Regex::new(r"\.\s*(?:Proceedings|Proc\.)\s+of").unwrap(),
            // Common venues/publishers
            Regex::new(r"\.\s*(?:IEEE|ACM|USENIX|NDSS|arXiv|Nature|Science)").unwrap(),
            Regex::new(r"\.\s*(?:Journal|Trans\.|Transactions|Review)\s+(?:of|on)").unwrap(),
            Regex::new(r"\.\s*[A-Z][a-zA-Z\s]+(?:Access|Journal|Review|Transactions)").unwrap(),
            Regex::new(r"\.\s*(?:Springer|Elsevier|Wiley|Cambridge|Oxford)\b").unwrap(),
            // Volume without journal name
            Regex::new(r"\s+\d+\s*\(\d+\)\s*[,:]\s*\d+[\u{2013}\-]").unwrap(),
            // DOI/URL
            Regex::new(r",?\s+doi:\s*10\.").unwrap(),
            Regex::new(r"\.\s*https?://").unwrap(),
            // Year patterns
            Regex::new(r"\s+\((?:19|20)\d{2}\)\s*[,.]?\s*(?:https?://|$)").unwrap(),
            Regex::new(r"\s+\((?:19|20)\d{2}\)\s*,").unwrap(),
            Regex::new(r"\.\s*pp?\.?\s*\d+").unwrap(),
            // Venue name with year: ". Venue Name (2020)"
            Regex::new(r"\.\s+[A-Z][A-Za-z\s]+\s+\(\d{4}\)").unwrap(),
        ]
    });

    let mut end = text.len();
    for re in PATTERNS.iter() {
        if let Some(m) = re.find(text) {
            end = end.min(m.start());
        }
    }
    end
}

/// Check if extracted text looks like journal metadata rather than a title.
fn is_journal_metadata(text: &str) -> bool {
    let text = text.trim();
    if text.is_empty() {
        return false;
    }

    static PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            // "In: " followed by venue markers (not just any "In ")
            Regex::new(r"(?i)^In:\s").unwrap(),
            // "In Proceedings..." or "In 2019 IEEE..." (venue patterns, not titles like "In numeris veritas")
            Regex::new(r"(?i)^In\s+(?:Proceedings|Proc\.)").unwrap(),
            Regex::new(r"(?i)^In\s+\d{4}\s+(?:IEEE|ACM|USENIX)").unwrap(),
            // Journal Vol(Issue), Pages (Year): "Educational Researcher 13(6), 4–16 (1984)"
            Regex::new(
                r"^[A-Z][A-Za-z\s&\-]+\s+\d+\s*\(\d+\)\s*[,:]\s*\d+[\u{2013}\-]\d+\s*\(\d{4}\)",
            )
            .unwrap(),
            // Journal Vol:Pages (Year): "Nature 123:456-789 (2020)"
            Regex::new(r"^[A-Z][A-Za-z\s&\-]+\s+\d+\s*:\s*\d+[\u{2013}\-]\d+\s*\(\d{4}\)").unwrap(),
            // Journal with acronym in parens: "Journal of the ACM (JACM) 32(2)"
            Regex::new(r"^[A-Z][A-Za-z\s]+\([A-Z]+\)\s+\d+\s*\(\d+\)").unwrap(),
            // Short journal: "Nature 299(5886)"
            Regex::new(r"^(?:Nature|Science|Cell|PNAS|PLoS)\s+\d+\s*\(\d+\)").unwrap(),
            // Just volume/page: "13(6), 4–16 (1984)"
            Regex::new(r"^\d+\s*\(\d+\)\s*[,:]\s*\d+[\u{2013}\-]\d+").unwrap(),
            // Journal name;year format: "IEEE Trans... 2018;17(3)"
            Regex::new(r"^[A-Z][A-Za-z\s]+\d{4};\d+").unwrap(),
        ]
    });

    PATTERNS.iter().any(|re| re.is_match(text))
}

/// Check if extracted text is just a venue/journal name, not a paper title.
fn is_venue_only(text: &str) -> bool {
    let text = text.trim();
    if text.is_empty() {
        return false;
    }

    static VENUE_ONLY_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            Regex::new(r"(?i)^(?:SIAM|IEEE|ACM|PNAS)\s+(?:Journal|Transactions|Review)").unwrap(),
            Regex::new(r"(?i)^(?:Journal|Transactions|Proceedings)\s+(?:of|on)\s+").unwrap(),
            Regex::new(r"(?i)^Advances\s+in\s+Neural").unwrap(),
        ]
    });

    VENUE_ONLY_PATTERNS.iter().any(|re| re.is_match(text))
}

/// Check if extracted text is an IEEE ALL CAPS author list, not a paper title.
fn is_likely_author_list(text: &str) -> bool {
    let text = text.trim();
    if text.is_empty() {
        return false;
    }

    static AUTHOR_LIST_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            // SURNAME, I., SURNAME, I.
            Regex::new(r"^[A-Z]{2,}\s*,\s*[A-Z]\.\s*,\s*[A-Z]{2,}\s*,\s*[A-Z]\.").unwrap(),
            // SURNAME, I., AND SURNAME
            Regex::new(r"^[A-Z]{2,}\s*,\s*[A-Z]\.\s*,?\s*AND\s+[A-Z]").unwrap(),
            // SURNAME, AND I. SURNAME
            Regex::new(r"^[A-Z]{2,}\s*,\s*AND\s+[A-Z]\.\s*[A-Z]").unwrap(),
            // EL HOUSNI AND G. BOTREL (multi-word surname + AND)
            Regex::new(r"^[A-Z]{2,}\s+[A-Z]{2,}\s+AND\s+[A-Z]\.\s*[A-Z]").unwrap(),
            // SURNAME AND SURNAME, (two ALL CAPS surnames)
            Regex::new(r"^[A-Z]{2,}\s+AND\s+[A-Z]\.\s*[A-Z]{2,}\s*,").unwrap(),
            // Broken umlaut: B ¨UNZ, P. (diacritic separated from letter)
            Regex::new(r"^[A-Z]\s*[\u{00A8}\u{00B4}\u{0060}]\s*[A-Z]+\s*,\s*[A-Z]\.").unwrap(),
        ]
    });

    AUTHOR_LIST_PATTERNS.iter().any(|re| re.is_match(text))
}

fn try_org_doc(ref_text: &str) -> Option<(String, bool)> {
    static RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"^([A-Z][a-zA-Z\s]+):\s*(.+)").unwrap());

    let caps = RE.captures(ref_text)?;
    let after_colon = caps.get(2).unwrap().as_str().trim();

    static END_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            Regex::new(r"\s+\((?:19|20)\d{2}\)\s*[,.]?\s*(?:https?://|$)").unwrap(),
            Regex::new(r"\s+\((?:19|20)\d{2}\)\s*,").unwrap(),
            Regex::new(r"\.\s*https?://").unwrap(),
        ]
    });

    let mut title_end = after_colon.len();
    for re in END_PATTERNS.iter() {
        if let Some(m) = re.find(after_colon) {
            title_end = title_end.min(m.start());
        }
    }

    let title = after_colon[..title_end].trim();
    static TRAIL: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.\s*$").unwrap());
    let title = TRAIL.replace(title, "");

    if title.split_whitespace().count() >= 2 {
        Some((title.to_string(), false))
    } else {
        None
    }
}

fn try_springer_year(ref_text: &str) -> Option<(String, bool)> {
    static RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"\((\d{4}[a-z]?)\)\.?\s+").unwrap());

    let caps = RE.captures(ref_text)?;
    let match_pos = caps.get(0).unwrap().start();

    // Springer format has (Year) after authors, before title - typically in first 40% of text.
    // If (Year) appears in the latter part (>60%), it's likely journal metadata (e.g., "Journal 2 (2018)")
    // not the author-year pattern. Skip to let other handlers (like try_acm_year) match correctly.
    if match_pos > ref_text.len() * 60 / 100 {
        return None;
    }

    let after_year = &ref_text[caps.get(0).unwrap().end()..];

    // Journal name character class: letters, spaces, &, +, ®, en-dash, em-dash, hyphen
    static END_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        let j = r"[a-zA-Z\s&+\u{00AE}\u{2013}\u{2014}\-]"; // journal name chars
        vec![
            Regex::new(r"\.\s*[Ii]n:\s+").unwrap(),
            Regex::new(r"\.\s*[Ii]n\s+[A-Z]").unwrap(),
            Regex::new(r"\.\s*(?:Proceedings|IEEE|ACM|USENIX|arXiv)").unwrap(),
            Regex::new(&format!(r"\.\s*[A-Z]{}+\d+\s*\(\d+\)", j)).unwrap(),
            Regex::new(&format!(r"\.\s*[A-Z]{}+\d+:\d+", j)).unwrap(),
            Regex::new(&format!(r"\.\s*[A-Z]{}+,\s*\d+", j)).unwrap(),
            Regex::new(r"\.\s*https?://").unwrap(),
            Regex::new(r"\.\s*URL\s+").unwrap(),
            Regex::new(r"\.\s*Tech\.\s*rep\.").unwrap(),
            Regex::new(r"\.\s*pp?\.?\s*\d+").unwrap(),
            // Journal name after sentence-ending punctuation: "? JournalName, vol(issue)"
            Regex::new(&format!(r"[?!]\s+[A-Z]{}+,\s*\d+\s*\(", j)).unwrap(),
            // Journal after ? with volume:pages: "? JournalName, vol: pages"
            Regex::new(&format!(r"[?!]\s+[A-Z]{}+,\s*\d+\s*:", j)).unwrap(),
            // ". Journal Name (Year)" — e.g., ". Journal of Legal Analysis (2021)"
            Regex::new(
                r"\.\s*[A-Z][a-zA-Z\s&+\u{00AE}\u{2013}\u{2014}\-]{5,}\s*\((?:19|20)\d{2}\)",
            )
            .unwrap(),
        ]
    });

    let mut title_end = after_year.len();
    for re in END_PATTERNS.iter() {
        if let Some(m) = re.find(after_year) {
            let candidate = if after_year
                .as_bytes()
                .get(m.start())
                .is_some_and(|&b| b == b'?' || b == b'!')
            {
                m.start() + 1
            } else {
                m.start()
            };
            title_end = title_end.min(candidate);
        }
    }

    let title = after_year[..title_end].trim();
    static TRAIL: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.\s*$").unwrap());
    let title = TRAIL.replace(title, "");

    if title.is_empty() {
        None
    } else {
        Some((title.to_string(), false))
    }
}

fn try_acm_year(ref_text: &str) -> Option<(String, bool)> {
    // ". YYYY[a-z]. Title" — require \s+ after year to avoid matching DOIs
    // Optional letter suffix for disambiguated years (e.g. "2022b")
    // Also handles ACM "[n. d.]" or "[n.d.]" (no date) marker
    static RE: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"\.\s*(?:(?:19|20)\d{2}[a-z]?|\[n\.?\s*d\.?\])\.\s+").unwrap());

    let caps = RE.captures(ref_text)?;
    let after_year = &ref_text[caps.get(0).unwrap().end()..];

    // Journal name character class: letters, spaces, &, +, ®, en-dash, em-dash, hyphen
    static END_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        let j = r"[a-zA-Z\s&+\u{00AE}\u{2013}\u{2014}\-]"; // journal name chars
        vec![
            Regex::new(r"\.\s*[Ii]n\s+[A-Z]").unwrap(),
            Regex::new(r"\.\s*(?:Proceedings|IEEE|ACM|USENIX|arXiv)").unwrap(),
            Regex::new(r"\s+doi:").unwrap(),
            // Journal name after sentence-ending punctuation: "? JournalName, vol(issue)"
            Regex::new(&format!(r"[?!]\s+[A-Z]{}+,\s*\d+\s*\(", j)).unwrap(),
            // Journal after ? with volume:issue pattern: "? JournalName, vol: pages"
            Regex::new(&format!(r"[?!]\s+[A-Z]{}+,\s*\d+\s*:", j)).unwrap(),
            // Period then journal + volume/issue: ". JournalName, vol(issue)"
            Regex::new(&format!(r"\.\s*[A-Z]{}+,\s*\d+\s*\(", j)).unwrap(),
            // Period then journal + volume:pages: ". JournalName, vol: pages"
            Regex::new(&format!(r"\.\s*[A-Z]{}+,\s*\d+\s*:", j)).unwrap(),
            // Period then journal name + comma + volume (no parens/colon): ". JournalName, vol"
            // Catches "Foundations and Trends® in Human–Computer Interaction, 14(4–5)"
            Regex::new(&format!(r"\.\s*[A-Z]{}{{10,}},\s*\d+", j)).unwrap(),
            // ". Journal Name (Year)" — e.g., ". Journal of Legal Analysis (2021)"
            Regex::new(
                r"\.\s*[A-Z][a-zA-Z\s&+\u{00AE}\u{2013}\u{2014}\-]{5,}\s*\((?:19|20)\d{2}\)",
            )
            .unwrap(),
            // ". https://" — URL after period
            Regex::new(r"\.\s*https?://").unwrap(),
        ]
    });

    let mut title_end = after_year.len();
    for re in END_PATTERNS.iter() {
        if let Some(m) = re.find(after_year) {
            // For patterns anchored on ? or !, keep the punctuation mark
            let candidate = if after_year
                .as_bytes()
                .get(m.start())
                .is_some_and(|&b| b == b'?' || b == b'!')
            {
                m.start() + 1
            } else {
                m.start()
            };
            title_end = title_end.min(candidate);
        }
    }

    let title = after_year[..title_end].trim();
    static TRAIL: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.\s*$").unwrap());
    let title = TRAIL.replace(title, "");

    if title.is_empty() {
        None
    } else {
        Some((title.to_string(), false))
    }
}

/// Handle arXiv preprint format: "Authors. Title. Year. arXiv: ID"
/// In this format, the title comes BEFORE the year, followed by arXiv.
fn try_arxiv_preprint(ref_text: &str) -> Option<(String, bool)> {
    // Match pattern: ". YEAR. arXiv:" or ". YEAR. arXiv "
    static RE: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"\.\s*(?:19|20)\d{2}\.\s*arXiv[:\s]").unwrap());

    let m = RE.find(ref_text)?;
    let before_year = &ref_text[..m.start()];

    // Find the title: look for the last ". X" pattern (sentence boundary) before the year
    // where X is an uppercase letter or digit that starts the title
    // This handles: "Author Name. Title Here. YEAR."
    static TITLE_START: Lazy<Regex> = Lazy::new(|| {
        // Match ". " followed by uppercase letter (title start)
        // We'll find ALL such matches and pick the LAST one closest to the year
        Regex::new(r#"\.\s+([A-Z0-9"\u{201c}])"#).unwrap()
    });

    // Find all potential title starts and pick the last one (closest to the year)
    let mut title_start_pos = None;
    for caps in TITLE_START.captures_iter(before_year) {
        if let Some(m) = caps.get(1) {
            title_start_pos = Some(m.start());
        }
    }

    let title_start = title_start_pos?;
    let title = before_year[title_start..].trim();

    // Remove trailing period
    let title = title.strip_suffix('.').unwrap_or(title).trim();

    if title.split_whitespace().count() >= 2 {
        Some((title.to_string(), false))
    } else {
        None
    }
}

fn try_venue_marker(ref_text: &str) -> Option<(String, bool)> {
    static VENUE_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            Regex::new(r"\.\s*[Ii]n:\s+(?:Proceedings|Workshop|Conference|Symposium|IFIP|IEEE|ACM)").unwrap(),
            Regex::new(r"\.\s*[Ii]n:\s+[A-Z]").unwrap(),
            Regex::new(r"\.\s*[Ii]n\s+(?:Proceedings|Workshop|Conference|Symposium|AAAI|IEEE|ACM|USENIX)").unwrap(),
            Regex::new(r"\.\s*[Ii]n\s+[A-Z][a-z]+\s+(?:Conference|Workshop|Symposium)").unwrap(),
            Regex::new(r"\.\s*[Ii]n\s+(?:The\s+)?(?:\w+\s+)+(?:International\s+)?(?:Conference|Workshop|Symposium)").unwrap(),
            Regex::new(r"\.\s*(?:NeurIPS|ICML|ICLR|CVPR|ICCV|ECCV|AAAI|IJCAI|CoRR|JMLR),").unwrap(),
            Regex::new(r"\.\s*arXiv\s+preprint").unwrap(),
            Regex::new(r"\.\s*[Ii]n\s+[A-Z]").unwrap(),
            Regex::new(r",\s*(?:19|20)\d{2}\.\s*(?:URL|$)").unwrap(),
            Regex::new(r",\s*(?:19|20)\d{2}\.\s*$").unwrap(),
        ]
    });

    for vp in VENUE_PATTERNS.iter() {
        if let Some(venue_match) = vp.find(ref_text) {
            let before_venue = ref_text[..venue_match.start()].trim();

            // First try: split into sentences
            let parts = split_sentences_skip_initials(before_venue);
            if parts.len() >= 2 {
                let title = parts[1].trim();
                static TRAIL: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.\s*$").unwrap());
                let title = TRAIL.replace(title, "");
                if !title.is_empty() {
                    // Verify it doesn't look like authors
                    static AUTHOR_CHECK: Lazy<Regex> =
                        Lazy::new(|| Regex::new(r"^[A-Z][a-z]+\s+[A-Z][a-z]+,").unwrap());
                    if !AUTHOR_CHECK.is_match(&title) {
                        return Some((title.to_string(), false));
                    }
                }
            }

            // Second try: look for author initial pattern followed by title
            static AUTHOR_END: Lazy<Regex> = Lazy::new(|| {
                Regex::new(r"(?:,\s+[A-Z]\.(?:[-\s]+[A-Z]\.)*|(?:Jr|Sr|III|II|IV)\.)\s+(.)")
                    .unwrap()
            });
            let all_matches: Vec<_> = AUTHOR_END.captures_iter(before_venue).collect();

            for caps in all_matches.iter().rev() {
                let title_start_match = caps.get(1).unwrap();
                let remaining = &before_venue[title_start_match.start()..];

                // Skip if looks like another author
                static AUTHOR_LIKE: Lazy<Regex> =
                    Lazy::new(|| Regex::new(r"^[A-Z]\.,|^[A-Z][a-z]+,").unwrap());
                if AUTHOR_LIKE.is_match(remaining) {
                    continue;
                }

                let title = remaining.trim();
                static TRAIL2: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.\s*$").unwrap());
                let title = TRAIL2.replace(title, "");
                if !title.is_empty() {
                    static AUTHOR_CHECK2: Lazy<Regex> =
                        Lazy::new(|| Regex::new(r"^[A-Z][a-z]+,\s+[A-Z]\.").unwrap());
                    if !AUTHOR_CHECK2.is_match(&title) {
                        return Some((title.to_string(), false));
                    }
                }
                break;
            }

            break; // Only try the first matching venue pattern
        }
    }
    None
}

fn try_journal(ref_text: &str) -> Option<(String, bool)> {
    static RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(r"(?i)\.\s*([A-Z][^.]+(?:Journal|Review|Transactions|Letters|Magazine|Science|Nature|Processing|Advances)[^.]*),\s*(?:vol\.|Volume|\d+\(|\d+,)").unwrap()
    });

    let m = RE.find(ref_text)?;
    let before_journal = ref_text[..m.start()].trim();
    let parts = split_sentences_skip_initials(before_journal);
    if parts.len() >= 2 {
        let title = parts[1].trim();
        if !title.is_empty() {
            return Some((title.to_string(), false));
        }
    }
    None
}

fn try_elsevier_journal(ref_text: &str) -> Option<(String, bool)> {
    static RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(r"\.\s*([A-Z][A-Za-z\s]+)\s+(?:19|20)\d{2};\d+(?:\(\d+\))?").unwrap()
    });

    let m = RE.find(ref_text)?;
    let before_journal = ref_text[..m.start()].trim();
    let parts = split_sentences_skip_initials(before_journal);
    if parts.len() >= 2 {
        let title = parts.last().unwrap().trim();
        static TRAIL: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.\s*$").unwrap());
        let title = TRAIL.replace(title, "");
        if !title.is_empty() {
            return Some((title.to_string(), false));
        }
    }
    None
}

fn try_chinese_allcaps(ref_text: &str) -> Option<(String, bool)> {
    // Chinese ALL CAPS: "SURNAME I, SURNAME I, et al. Title[J]. Venue"
    // Key difference from Western: single-letter initial without period after surname
    static CHINESE_CAPS: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"^[A-Z]{2,}\s+[A-Z](?:,|\s|$)").unwrap());
    if !CHINESE_CAPS.is_match(ref_text) {
        return None;
    }

    // Find end of author list at "et al." or transition to non-author text
    static ET_AL: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"(?i),?\s+et\s+al\.?\s*[,.]?\s*").unwrap());

    let after_authors_str: String = if let Some(m) = ET_AL.find(ref_text) {
        ref_text[m.end()..].trim().to_string()
    } else {
        // Find where ALL CAPS author pattern ends by scanning comma-separated parts
        static AUTHOR_PART: Lazy<Regex> =
            Lazy::new(|| Regex::new(r"^[A-Z]{2,}(?:\s+[A-Z](?:\s+[A-Z])?)?$").unwrap());
        let parts: Vec<&str> = ref_text.split(", ").collect();
        let mut title_start_idx = None;
        for (i, part) in parts.iter().enumerate() {
            let trimmed = part.trim();
            if AUTHOR_PART.is_match(trimmed) {
                continue;
            }
            title_start_idx = Some(i);
            break;
        }
        match title_start_idx {
            Some(idx) => parts[idx..].join(", ").trim().to_string(),
            None => return None,
        }
    };

    if after_authors_str.is_empty() {
        return None;
    }

    // Find where title ends — at Chinese citation markers or venue patterns
    static TITLE_END_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            Regex::new(r"\[J\]").unwrap(), // Chinese: journal
            Regex::new(r"\[C\]").unwrap(), // Chinese: conference
            Regex::new(r"\[M\]").unwrap(), // Chinese: book/monograph
            Regex::new(r"\[D\]").unwrap(), // Chinese: dissertation
            Regex::new(r"\.\s*[A-Z][a-zA-Z\s]+\d+\s*\(\d+\)").unwrap(), // ". Journal 34(5)"
            Regex::new(r"\.\s*[A-Z][a-zA-Z\s&+]+\d+:\d+").unwrap(), // ". Journal 34:123"
            Regex::new(r"\.\s*[A-Z][a-zA-Z\s&+]+,\s*\d+").unwrap(), // ". Journal, vol"
            Regex::new(r"\.\s*(?:19|20)\d{2}").unwrap(), // ". 2024"
            Regex::new(r"\.\s*https?://").unwrap(),
            Regex::new(r"\.\s*doi:").unwrap(),
        ]
    });

    let mut title_end = after_authors_str.len();
    for re in TITLE_END_PATTERNS.iter() {
        if let Some(m) = re.find(&after_authors_str) {
            title_end = title_end.min(m.start());
        }
    }

    let title = after_authors_str[..title_end].trim();
    static TRAIL: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.\s*$").unwrap());
    let title = TRAIL.replace(title, "");

    if title.is_empty() {
        None
    } else {
        Some((title.to_string(), false))
    }
}

fn try_all_caps_authors(ref_text: &str) -> Option<(String, bool)> {
    static STARTS_CAPS: Lazy<Regex> = Lazy::new(|| Regex::new(r"^[A-Z]{2,}").unwrap());
    if !STARTS_CAPS.is_match(ref_text) {
        return None;
    }

    // Skip Chinese ALL CAPS pattern (handled by try_chinese_allcaps)
    static CHINESE_CAPS: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"^[A-Z]{2,}\s+[A-Z](?:,|\s)").unwrap());
    if CHINESE_CAPS.is_match(ref_text) {
        return None;
    }

    // Find title start: period + space + Capital followed by lowercase
    static TITLE_START: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"\.\s+([A-Z][a-z]*\s+[a-z])").unwrap());
    let caps = TITLE_START.captures(ref_text)?;
    let title_text = &ref_text[caps.get(1).unwrap().start()..];

    static END_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            Regex::new(r"\.\s*[Ii]n\s+[A-Z]").unwrap(),
            Regex::new(r"\.\s*(?:Proceedings|IEEE|ACM|USENIX|NDSS|arXiv|Technical\s+report)")
                .unwrap(),
            Regex::new(r"\.\s*[A-Z][a-z]+\s+\d+,\s*\d+\s*\(").unwrap(),
            Regex::new(r"\.\s*(?:Ph\.?D\.?\s+thesis|Master.s\s+thesis)").unwrap(),
        ]
    });

    let mut title_end = title_text.len();
    for re in END_PATTERNS.iter() {
        if let Some(m) = re.find(title_text) {
            title_end = title_end.min(m.start());
        }
    }

    if title_end > 0 {
        let title = title_text[..title_end].trim();
        static TRAIL: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.\s*$").unwrap());
        let title = TRAIL.replace(title, "");
        if !title.is_empty() {
            return Some((title.to_string(), false));
        }
    }
    None
}

fn try_bracket_code(ref_text: &str) -> Option<(String, bool)> {
    // Bracket citation format: "[ACGH20] Authors. Title. In Venue"
    static BRACKET_RE: Lazy<Regex> =
        Lazy::new(|| Regex::new(r"^\[([A-Z]+\d+[a-z]?)\]\s*").unwrap());

    let caps = BRACKET_RE.captures(ref_text)?;
    let after_bracket = &ref_text[caps.get(0).unwrap().end()..];

    // Split into sentences and find author-title boundary
    let sentences = split_sentences_skip_initials(after_bracket);
    if sentences.len() < 2 {
        return None;
    }

    // First sentence is authors, look for title in subsequent sentences
    for i in 0..sentences.len().saturating_sub(1) {
        let sent = &sentences[i];
        // Check if this sentence ends with what looks like an author name
        // and next doesn't start with "In" (venue marker)
        static AUTHOR_END_RE: Lazy<Regex> =
            Lazy::new(|| Regex::new(r"(?:and\s+)?[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*$").unwrap());
        static IN_START_RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"^In\s+").unwrap());

        if AUTHOR_END_RE.is_match(sent) {
            let next = &sentences[i + 1];
            if !IN_START_RE.is_match(next) && next.starts_with(|c: char| c.is_uppercase()) {
                // Found the title. Reconstruct it and find where it ends (at "In Venue")
                let remaining: String = sentences[i + 1..].join(". ");
                let title_end = remaining.find(". In ").unwrap_or(remaining.len());
                let title = remaining[..title_end].trim();
                if !title.is_empty() {
                    return Some((title.to_string(), false));
                }
            }
        }
    }
    None
}

fn try_author_particles(ref_text: &str) -> Option<(String, bool)> {
    // Handles author names with particles: von, van der, Le, etc.
    // Pattern: "I. Name, I. Name, and I. Name. Title"
    // The key is finding ", and Initial. Surname. TitleStart"
    static AND_AUTHOR_TITLE_RE: Lazy<Regex> = Lazy::new(|| {
        // Initial pattern: single letter "A." or multi-letter "Yu." (Russian/Chinese patronymics)
        // Also handles compound initials like "A.-B." or "A. B."
        // Use lazy quantifier (*?) to avoid matching too many initials
        let initial = r"[\x41-\x5A\u{00C0}-\u{00D6}\u{00D8}-\u{00DE}\u{0027}\u{0060}\u{00B4}](?:[a-z]{0,2})?\.(?:[\s\-]*[A-Z](?:[a-z]{0,2})?\.)*?";
        let particle =
            r"(?:(?:von|van|de|del|della|di|da|dos|das|du|le|la|les|den|der|ten|ter|op|het)\s+)?";
        let surname_chars = r"[A-Za-z\u{00C0}-\u{024F}\u{0027}\u{0060}\u{00B4}\u{2019}\-]";
        // Require at least 2 chars in surname to avoid matching single-letter initials like "G."
        // Use lazy quantifier (*?) to avoid consuming title words as part of surname
        let surname = format!(
            r"{}{}{{2,}}(?:\s+{}+)*?",
            particle, surname_chars, surname_chars
        );
        let pattern = format!(
            r#",?\s+and\s+{}\s*{}\.\s+([A-Z\u{{00C0}}-\u{{00D6}}][a-z]|[A-Z]\s+[a-z]|[0-9]|["\u{{201c}}\u{{201d}}])"#,
            initial, surname,
        );
        Regex::new(&pattern).unwrap()
    });

    let caps = AND_AUTHOR_TITLE_RE.captures(ref_text)?;
    let title_start = caps.get(1).unwrap().start();
    let title_text = &ref_text[title_start..];

    // Find where title ends (venue/year markers)
    static TITLE_END_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            Regex::new(r"\.\s+In\s+").unwrap(),
            Regex::new(r"\s+In\s+Proceedings").unwrap(),
            Regex::new(r"\.\s+(?:Proc\.|Proceedings\s+of)").unwrap(),
            Regex::new(r"\.\s+(?:IEEE|ACM|USENIX|NDSS|CCS|AAAI|ICML|NeurIPS|EuroS&P)\b").unwrap(),
            Regex::new(r"\.\s+[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\s+\d{4}").unwrap(),
            Regex::new(r"\.\s+[A-Z][a-z]+(?:\s*&\s*[A-Z][a-z]+)+").unwrap(),
            Regex::new(r"\.\s+arXiv\s+preprint").unwrap(),
            Regex::new(r",\s+(?:vol\.|pp\.|pages)\s").unwrap(),
            Regex::new(r",\s+\d{4}\.\s*$").unwrap(),
            Regex::new(r",\s+\d+\(\d+\)").unwrap(),
            Regex::new(r"\.\s+(?:Springer|Elsevier|Wiley|Nature|Science|PLOS|Oxford|Cambridge)\b")
                .unwrap(),
            Regex::new(r"\.\s+(?:The\s+)?(?:Annals|Journal|Proceedings)\s+of\b").unwrap(),
            Regex::new(r"\.\s+Journal\s+of\s+[A-Z]").unwrap(),
            Regex::new(r"\.\s+[A-Z][a-z]+(?:\s+[A-Z][a-z]+)+,\s*\d").unwrap(),
            Regex::new(r"\.\s+[A-Z][a-z]+(?:\s+[A-Z][a-z]+)+\s+\d+[:(]").unwrap(),
        ]
    });

    let mut title_end = title_text.len();
    for re in TITLE_END_PATTERNS.iter() {
        if let Some(m) = re.find(title_text) {
            title_end = title_end.min(m.start());
        }
    }

    let title = title_text[..title_end].trim();
    static TRAIL: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.\s*$").unwrap());
    let title = TRAIL.replace(title, "");

    if title.is_empty() {
        None
    } else {
        Some((title.to_string(), false))
    }
}

/// Book citation format: "F. M. Author and F. M. Author, Title. Publisher, Year."
/// The key difference from journal format is: authors end with COMMA (not period),
/// followed by title, then period, then publisher.
fn try_book_citation(ref_text: &str) -> Option<(String, bool)> {
    // Pattern: "and Initial. Surname, Title"
    // where title starts with capital letter and contains lowercase (not all caps)
    static BOOK_AUTHOR_RE: Lazy<Regex> = Lazy::new(|| {
        // Match: "and I. I. Surname," or "and I. Surname," where Surname is 2+ letters
        Regex::new(r"(?i)\band\s+(?:[A-Z]\.\s*)+[A-Za-z\u{00C0}-\u{024F}'-]{2,},\s*([A-Z][a-z])")
            .unwrap()
    });

    let caps = BOOK_AUTHOR_RE.captures(ref_text)?;
    let title_start_match = caps.get(1)?;
    let title_start = title_start_match.start();
    let title_text = &ref_text[title_start..];

    // Find where title ends: first period followed by space and then publisher/year
    // Publishers: "MIT press", "Springer", "Elsevier", "Cambridge", "Oxford", etc.
    // Or: capital word followed by comma and 4-digit year
    static TITLE_END_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
        vec![
            // Period followed by publisher name
            Regex::new(r"\.\s+(?:MIT|Cambridge|Oxford|Springer|Elsevier|Wiley|Academic|Prentice|McGraw|Addison|O'Reilly|Morgan|CRC|IEEE|ACM)\b").unwrap(),
            // Period followed by "X press" or "X Press"
            Regex::new(r"\.\s+[A-Z][a-z]+\s+[Pp]ress\b").unwrap(),
            // Period followed by "X Publishing"
            Regex::new(r"\.\s+[A-Z][a-z]+\s+Publishing\b").unwrap(),
            // Period followed by capitalized word, comma, year
            Regex::new(r"\.\s+[A-Z][a-z]+,\s*(?:19|20)\d{2}").unwrap(),
        ]
    });

    let mut title_end = title_text.len();
    for re in TITLE_END_PATTERNS.iter() {
        if let Some(m) = re.find(title_text) {
            title_end = title_end.min(m.start());
        }
    }

    // If no publisher pattern found, look for first real period
    if title_end == title_text.len() {
        // Find first period that's not after a single letter (initial)
        for (i, _) in title_text.match_indices('.') {
            if i > 0 {
                let char_before = title_text.as_bytes().get(i - 1).copied().unwrap_or(0);
                // Skip if it's an initial (single capital letter before period)
                if char_before.is_ascii_uppercase() {
                    let two_before = if i >= 2 {
                        title_text.as_bytes().get(i - 2).copied().unwrap_or(0)
                    } else {
                        0
                    };
                    if !two_before.is_ascii_alphabetic() {
                        continue; // This is an initial like "A."
                    }
                }
                title_end = i;
                break;
            }
        }
    }

    let title = title_text[..title_end].trim();
    if title.len() < 10 {
        return None; // Too short to be a real title
    }

    Some((title.to_string(), false))
}

fn try_direct_in_venue(ref_text: &str) -> Option<(String, bool)> {
    // Fallback: "Title. In Something" where title starts with capital and has 15+ chars
    static RE: Lazy<Regex> = Lazy::new(|| {
        Regex::new(r"^([A-Z][^.]{15,}?)\.\s+In\s+(?:[A-Z]|Proceedings|Proc\.)").unwrap()
    });

    let caps = RE.captures(ref_text)?;
    let title = caps.get(1).unwrap().as_str().trim();

    if title.split_whitespace().count() >= 4 {
        Some((title.to_string(), false))
    } else {
        None
    }
}

fn try_fallback_sentence(ref_text: &str) -> Option<(String, bool)> {
    let sentences = split_sentences_skip_initials(ref_text);
    if sentences.len() < 2 {
        return None;
    }

    let mut potential_title = sentences[1].trim().to_string();

    // Check if it looks like authors (high ratio of capitalized words + "and")
    let words: Vec<&str> = potential_title.split_whitespace().collect();
    if !words.is_empty() {
        static CAP_WORD: Lazy<Regex> = Lazy::new(|| Regex::new(r"^[A-Z][a-z]+$").unwrap());
        let cap_words = words.iter().filter(|w| CAP_WORD.is_match(w)).count();
        let and_count = words.iter().filter(|w| w.to_lowercase() == "and").count();

        if (cap_words as f64 / words.len() as f64) > 0.7 && and_count > 0 {
            // Try third sentence
            if sentences.len() >= 3 {
                potential_title = sentences[2].trim().to_string();
            }
        }
    }

    // Skip if starts with "In " (venue)
    static IN_RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"^[Ii]n\s+").unwrap());
    if IN_RE.is_match(&potential_title) {
        return None;
    }

    if potential_title.is_empty() {
        None
    } else {
        Some((potential_title, false))
    }
}

// ───────────────── Sentence splitting ─────────────────

/// Split text into sentences, but skip periods that are author initials
/// (e.g., "M." "J.") or mid-sentence abbreviations (e.g., "vs.").
fn split_sentences_skip_initials(text: &str) -> Vec<String> {
    static PERIOD_SPACE: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.\s+").unwrap());

    // Regex for matching characters in surname (letters, accents, apostrophes, hyphens)
    // Note: Rust regex doesn't support Unicode properties the same way, so we use
    // character classes for common diacritics
    static AUTHOR_AFTER: Lazy<Vec<Regex>> = Lazy::new(|| {
        let sc = r"[a-zA-Z\u{00A0}-\u{017F}'\-`\u{00B4}]"; // surname chars
        vec![
            // Surname followed by comma: "Smith,"
            Regex::new(&format!(r"^([A-Z]{}+)\s*,", sc)).unwrap(),
            // Surname + Initial(s) + comma: "Smith JK,"
            Regex::new(&format!(r"^([A-Z]{}+)\s+([A-Z][A-Z]?)\s*,", sc)).unwrap(),
            // Surname + Initial comma: "Smith J,"
            Regex::new(&format!(r"^([A-Z]{}+)\s+[A-Z]{{1,2}},", sc)).unwrap(),
            // "and Surname" pattern
            Regex::new(r"(?i)^and\s+[A-Z]").unwrap(),
            // Another initial: "X."
            Regex::new(r"^[A-Z]\.").unwrap(),
            // Compound initial: "X.-Y."
            Regex::new(r"^[A-Z]\.-[A-Z]\.").unwrap(),
            // Surname + period + Capital: "Smith. X"
            Regex::new(&format!(r"^([A-Z]{}+)\.\s+[A-Z]", sc)).unwrap(),
            // Surname + "and" + Capital
            Regex::new(&format!(r"(?i)^([A-Z]{}+)\s+and\s+[A-Z]", sc)).unwrap(),
            // Multi-part surname: "Van Goethem,"
            Regex::new(&format!(r"^([A-Z]{}+)\s+([A-Z]{}+)\s*,", sc, sc)).unwrap(),
            // Middle initial without period: "D Kaplan,"
            Regex::new(&format!(r"^[A-Z]\s+({}+)\s*,", sc)).unwrap(),
        ]
    });

    let mut sentences = Vec::new();
    let mut current_start = 0;

    for m in PERIOD_SPACE.find_iter(text) {
        let pos = m.start();
        if pos == 0 {
            continue;
        }

        let char_before = text.as_bytes()[pos - 1];

        // Check if period follows a single capital letter (potential initial)
        if char_before.is_ascii_uppercase()
            && (pos == 1 || !text.as_bytes()[pos - 2].is_ascii_alphabetic())
        {
            let after_period = &text[m.end()..];
            let is_author = AUTHOR_AFTER.iter().any(|re| re.is_match(after_period));
            if is_author {
                continue; // Skip — this is an author initial
            }
        }

        // Check for multi-letter initials (2-3 chars like "Yu." in Russian/Chinese names)
        // e.g., "A. Yu. Veretennikov" where "Yu." is a patronymic initial
        {
            let mut word_start = pos - 1;
            while word_start > 0 && text.as_bytes()[word_start - 1].is_ascii_alphabetic() {
                word_start -= 1;
            }
            let word_len = pos - word_start;
            // Short words (2-3 chars) starting with capital followed by surname
            if (2..=3).contains(&word_len) && text.as_bytes()[word_start].is_ascii_uppercase() {
                let after_period = &text[m.end()..];
                let is_author = AUTHOR_AFTER.iter().any(|re| re.is_match(after_period));
                if is_author {
                    continue; // Skip — this is a multi-letter initial
                }
            }
        }

        // Check for mid-sentence abbreviation
        let mut word_start = pos - 1;
        while word_start > 0 && text.as_bytes()[word_start - 1].is_ascii_alphabetic() {
            word_start -= 1;
        }
        // Ensure word_start is on a char boundary (backward byte walk may land inside multi-byte UTF-8)
        while word_start > 0 && !text.is_char_boundary(word_start) {
            word_start -= 1;
        }
        let word_before = &text[word_start..pos];
        if MID_SENTENCE_ABBREVIATIONS.contains(word_before.to_lowercase().as_str()) {
            continue;
        }

        // This is a real sentence boundary
        let sentence = text[current_start..pos].trim();
        if !sentence.is_empty() {
            sentences.push(sentence.to_string());
        }
        current_start = m.end();
    }

    // Add remaining text
    let remaining = text[current_start..].trim();
    if !remaining.is_empty() {
        sentences.push(remaining.to_string());
    }

    sentences
}

// ───────────────── Title cleaning helpers ─────────────────

fn truncate_at_sentence_end(title: &str) -> String {
    for m in title.match_indices('.') {
        let pos = m.0;
        // Find start of segment
        let last_period = title[..pos].rfind('.').map(|p| p + 1).unwrap_or(0);
        let last_space = title[..pos].rfind(' ').map(|p| p + 1).unwrap_or(0);
        let segment_start = last_period.max(last_space);
        let segment = &title[segment_start..pos];

        // If segment > 2 chars, it's a real sentence end
        // OR 2-char ALL-CAPS segment (acronyms like "AI.", "ML.")
        if segment.len() > 2 || (segment.len() == 2 && segment.chars().all(|c| c.is_uppercase())) {
            // Skip if period is immediately followed by a letter (product names)
            // or a digit (version numbers like ASN.1, Web 2.0, 802.11)
            if pos + 1 < title.len()
                && (title.as_bytes()[pos + 1].is_ascii_alphabetic()
                    || title.as_bytes()[pos + 1].is_ascii_digit())
            {
                continue;
            }
            // Skip if followed by space + digit (version number like "Flux. 1")
            let bytes = title.as_bytes();
            if pos + 2 < title.len()
                && bytes.get(pos + 1) == Some(&b' ')
                && bytes.get(pos + 2).is_some_and(|b| b.is_ascii_digit())
            {
                continue;
            }
            return title[..pos].to_string();
        }
    }
    title.to_string()
}

/// The built-in default cutoff patterns. Exposed as `pub(crate)` so config resolution can use them.
pub(crate) static DEFAULT_CUTOFF_PATTERNS: Lazy<Vec<Regex>> = Lazy::new(|| {
    let j = r"[a-zA-Z&+\u{00AE}\u{2013}\u{2014}\-]"; // journal name chars (no \s)
    vec![
        // Chinese citation markers: [J]=journal, [C]=conference, [M]=book, [D]=dissertation
        Regex::new(r"\[J\].*$").unwrap(),
        Regex::new(r"\[C\].*$").unwrap(),
        Regex::new(r"\[M\].*$").unwrap(),
        Regex::new(r"\[D\].*$").unwrap(),
        Regex::new(r"(?i)\.\s*[Ii]n:\s+[A-Z].*$").unwrap(),
        Regex::new(r"(?i)\.\s*[Ii]n\s+[A-Z].*$").unwrap(),
        Regex::new(r"(?i)[.?!]\s*(?:Proceedings|Conference|Workshop|Symposium|IEEE|ACM|USENIX|AAAI|EMNLP|NAACL|arXiv|Available|CoRR|PACM[- ]?\w+|JMLR|VLDB|SIGMOD|SIGKDD|PLDI|POPL|OOPSLA|SOSP|OSDI|IACR|Cryptology\s+ePrint).*$").unwrap(),
        Regex::new(r"(?i)[.?!]\s*(?:Advances\s+in|Journal\s+of|Transactions\s+of|Transactions\s+on|Communications\s+of).*$").unwrap(),
        Regex::new(r"(?i)[.?!]\s+International\s+Journal\b.*$").unwrap(),
        Regex::new(r"(?i)\.\s*[A-Z][a-z]+\s+(?:Journal|Review|Transactions|Letters|advances|Processing|medica|Intelligenz)\b.*$").unwrap(),
        Regex::new(r"(?i)\.\s*(?:Patterns|Data\s+&\s+Knowledge).*$").unwrap(),
        Regex::new(r"[.,]\s+[A-Z][a-z]+\s+\d+[,\s].*$").unwrap(),
        Regex::new(r"(?i),\s*volume\s+\d+.*$").unwrap(),
        Regex::new(r",\s*\d+\s*\(\d+\).*$").unwrap(),
        Regex::new(r",\s*\d+\s*$").unwrap(),
        Regex::new(r"\.\s*\d+\s*$").unwrap(),
        Regex::new(r"\.\s*https?://.*$").unwrap(),
        Regex::new(r"\.\s*ht\s*tps?://.*$").unwrap(),
        Regex::new(r"(?i),\s*(?:vol\.|pp\.|pages).*$").unwrap(),
        Regex::new(r"(?i)\.\s*Data\s+in\s+brief.*$").unwrap(),
        Regex::new(r"(?i)\.\s*Biochemia\s+medica.*$").unwrap(),
        Regex::new(r"(?i)\.\s*KI-K\u{00FC}nstliche.*$").unwrap(),
        Regex::new(r"\s+arXiv\s+preprint.*$").unwrap(),
        Regex::new(r"\s+arXiv:\d+.*$").unwrap(),
        Regex::new(r"\s+CoRR\s+abs/.*$").unwrap(),
        Regex::new(r"(?i),?\s*(?:January|February|March|April|May|June|July|August|September|October|November|December)\s+(?:19|20)\d{2}.*$").unwrap(),
        Regex::new(r"(?i)[.,]\s*[Aa]ccessed\s+.*$").unwrap(),
        Regex::new(r"\s*\(\d+[\u{2013}\-]\d*\)\s*$").unwrap(),
        Regex::new(r"\s*\(pp\.?\s*\d+[\u{2013}\-]\d*\)\s*$").unwrap(),
        Regex::new(r",?\s+\d+[\u{2013}\-]\d+\s*$").unwrap(),
        // Journal + volume/pages with expanded char class for &, +, ®, dashes
        Regex::new(&format!(r"\.\s*[A-Z](?:{}|\s)+,\s*\d+\s*[,:\s]\s*\d+[\u{{2013}}\-]?\d*.*$", j)).unwrap(),
        // Journal name after period with no volume (just ends): ". Big Data & Society, 1(1)"
        // These are caught by the volume/issue patterns above; this handles standalone names
        Regex::new(&format!(r"\.\s+(?:[A-Z](?:{}|\s)+[&+](?:{}|\s)+)\s*$", j, j)).unwrap(),
    ]
});

fn apply_cutoff_patterns_with_config(title: &str, config: &PdfParsingConfig) -> String {
    let patterns = config
        .venue_cutoff_patterns
        .resolve(&DEFAULT_CUTOFF_PATTERNS);

    let mut result = title.to_string();
    for re in patterns.iter() {
        result = re.replace(&result, "").to_string();
    }
    result
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_ieee_quoted_title() {
        let ref_text = r#"J. Smith, A. Jones, and C. Williams, "Detecting Fake References in Papers," in Proc. IEEE Conf., 2023."#;
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(from_quotes);
        assert!(title.contains("Detecting Fake References"));
    }

    #[test]
    fn test_acm_year_title() {
        let ref_text = "Smith, J. and Jones, A. 2022. A Novel Approach to Reference Detection. In Proceedings of ACM SIGIR.";
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(!from_quotes);
        assert!(title.contains("Novel Approach"));
    }

    #[test]
    fn test_clean_title_trailing_venue() {
        let title = "My Great Paper. In Proceedings of USENIX Security";
        let cleaned = clean_title(title, false);
        assert_eq!(cleaned, "My Great Paper");
    }

    #[test]
    fn test_clean_title_arxiv() {
        let title = "Some Title arXiv preprint arXiv:2301.12345";
        let cleaned = clean_title(title, false);
        assert_eq!(cleaned, "Some Title");
    }

    #[test]
    fn test_clean_title_from_quotes() {
        // From quotes: no sentence truncation
        let title = "A Short Sentence. With More Words Here";
        let cleaned_quotes = clean_title(title, true);
        // Should preserve multi-sentence for quoted titles
        assert!(cleaned_quotes.contains("More Words"));

        let cleaned_no_quotes = clean_title(title, false);
        // Should truncate at first sentence boundary
        assert!(!cleaned_no_quotes.contains("More Words"));
    }

    #[test]
    fn test_split_sentences_skip_initials() {
        let text = "J. Smith and A. Jones. A Novel Detection Method. In Proceedings.";
        let parts = split_sentences_skip_initials(text);
        assert_eq!(parts.len(), 3);
        assert!(parts[0].contains("Smith"));
        assert!(parts[1].contains("Novel Detection"));
    }

    #[test]
    fn test_split_sentences_middle_initial_no_period() {
        // "D Kaplan" has a middle initial without its period — should stay in author section
        let text = "J. D Kaplan, P. Dhariwal. Title here.";
        let parts = split_sentences_skip_initials(text);
        assert!(
            parts[0].contains("Kaplan"),
            "Kaplan should be in author segment: {:?}",
            parts
        );
        assert!(
            parts[0].contains("Dhariwal"),
            "Dhariwal should be in author segment: {:?}",
            parts
        );
    }

    #[test]
    fn test_split_sentences_middle_initial_no_period_variant() {
        // Multiple authors with missing-period initials, separated by commas
        let text = "A. B Smith, C. D Jones, E. Brown. Some interesting research.";
        let parts = split_sentences_skip_initials(text);
        assert!(
            parts[0].contains("Jones"),
            "Jones should be in author segment: {:?}",
            parts
        );
    }

    #[test]
    fn test_springer_year_format() {
        let ref_text =
            "Smith J, Jones A (2023) A novel approach to detection. Nature 500(3):123-456";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(title.contains("novel approach"));
    }

    #[test]
    fn test_empty_ref() {
        let (title, from_quotes) = extract_title_from_reference("");
        assert!(title.is_empty());
        assert!(!from_quotes);
    }

    #[test]
    fn test_journal_name_after_question_mark() {
        // Journal name "New media & society" should NOT be part of the title
        let ref_text = "Baek, Y. M.; Wojcieszak, M.; and Delli Carpini, M. X. 2012. Online versus face-to-face deliberation: Who? Why? What? With what effects? New media & society, 14(3): 363\u{2013}383";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            !cleaned.contains("New media"),
            "Journal name leaked into title: {}",
            cleaned,
        );
        assert!(
            cleaned.contains("With what effects?"),
            "Title should end with question mark: {}",
            cleaned,
        );
    }

    #[test]
    fn test_harvard_single_quoted_title() {
        // Harvard/APA style uses single quotes around the title
        let ref_text = "Biswas, A., Saha, K. and De Choudhury, M. (2025) \u{2018}Political Elites in the Attention Economy: Visibility Over Civility and Credibility?\u{2019}, Proceedings of the International AAAI Conference on Web and Social Media (ICWSM).";
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(from_quotes, "Should detect single-quoted title");
        assert!(
            title.contains("Political Elites"),
            "Title should contain 'Political Elites': {}",
            title,
        );
    }

    #[test]
    fn test_utf8_smart_quote_no_crash() {
        // Regression: smart quote before period should not cause UTF-8 panic
        let text = "Smith J. \u{201c}Some title\u{201d}. In Proceedings.";
        let parts = split_sentences_skip_initials(text);
        assert!(!parts.is_empty());
    }

    #[test]
    fn test_big_data_society_journal_leak() {
        // "Big Data & Society" should NOT be in the title (& in journal name)
        let ref_text = "Burrell, J. 2016. How the Machine \u{201c}Thinks\u{201d}: Understanding Opacity in Machine Learning Algorithms. Big Data & Society, 3(1)";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            !cleaned.contains("Big Data"),
            "Journal 'Big Data & Society' leaked into title: {}",
            cleaned,
        );
        assert!(
            cleaned.contains("Understanding Opacity"),
            "Title should contain 'Understanding Opacity': {}",
            cleaned,
        );
    }

    #[test]
    fn test_foundations_trends_journal_leak() {
        // "Foundations and Trends® in Human–Computer Interaction" should NOT be in the title
        let ref_text = "Metaxa, D.; Park, J. S.; Robertson, R. E.; Karahalios, K.; Wilson, C.; and Hancock, J. 2021. Auditing Algorithms: Understanding Algorithmic Systems from the Outside In. Foundations and Trends\u{00AE} in Human\u{2013}Computer Interaction, 14(4\u{2013}5)";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            !cleaned.contains("Foundations"),
            "Journal 'Foundations and Trends' leaked into title: {}",
            cleaned,
        );
        assert!(
            cleaned.contains("Outside In"),
            "Title should contain 'Outside In': {}",
            cleaned,
        );
    }

    #[test]
    fn test_communication_research_journal_leak() {
        // "Communication Research" should NOT be in the title — straight quotes
        let ref_text = "Marchal, N. 2021. \"Be nice or leave me alone\": An intergroup perspective on affective polarization in online political discussions. Communication Research, 49(3): 376\u{2013}398";
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, from_quotes);
        assert!(
            !cleaned.contains("Communication Research"),
            "Journal 'Communication Research' leaked into title (straight quotes): {}",
            cleaned,
        );

        // Also test with smart quotes (as commonly found in PDFs)
        let ref_text2 = "Marchal, N. 2021. \u{201c}Be nice or leave me alone\u{201d}: An intergroup perspective on affective polarization in online political discussions. Communication Research, 49(3): 376\u{2013}398";
        let (title2, from_quotes2) = extract_title_from_reference(ref_text2);
        let cleaned2 = clean_title(&title2, from_quotes2);
        assert!(
            !cleaned2.contains("Communication Research"),
            "Journal 'Communication Research' leaked into title (smart quotes): {}",
            cleaned2,
        );
    }

    #[test]
    fn test_social_media_plus_society_journal_leak() {
        // "Social Media + Society" should NOT be in the title (+ in journal name)
        let ref_text = "Zhao, H.; Wang, J.; and Hu, X. 2025. \u{201c}A wandering existence\u{201d}: Social media practices of Chinese youth in the context of platform-swinging. Social Media + Society, 11(1)";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            !cleaned.contains("Social Media + Society"),
            "Journal 'Social Media + Society' leaked into title: {}",
            cleaned,
        );
    }

    #[test]
    fn test_journal_after_period() {
        // "American Political Science Review" should not be in the title
        let ref_text = "Fishkin, J.; Siu, A.; Diamond, L.; and Bradburn, N. 2021. Is deliberation an antidote to extreme partisan polarization? Reflections on \u{201c}America in one room\u{201d}. American Political Science Review, 115(4): 1464\u{2013}1481";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            !cleaned.contains("American Political"),
            "Journal name leaked into title: {}",
            cleaned,
        );
    }

    // ───────────────── Tests for regexp_improvements.py ports ─────────────────

    #[test]
    fn test_chinese_allcaps_with_et_al() {
        let ref_text = "CAO X, YANG B, WANG K, et al. AI-empowered multiple access for 6G: A survey of spectrum sensing, protocol designs, and optimizations[J]. Proceedings of the IEEE, 2024, 112(9): 1264-1302.";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            cleaned.contains("AI-empowered multiple access for 6G"),
            "Should extract Chinese ALL CAPS title: {}",
            cleaned,
        );
        assert!(
            !cleaned.contains("[J]"),
            "Should not include [J] marker: {}",
            cleaned,
        );
    }

    #[test]
    fn test_chinese_allcaps_h_infinity() {
        let ref_text = "LIU Z, SABERI A, et al. H\u{221E} almost state synchronization for homogeneous networks[J]. IEEE Trans. Aut. Contr. 53 (2008), no. 4.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("almost state synchronization"),
            "Should extract title from Chinese ALL CAPS with H-infinity: {}",
            title,
        );
    }

    #[test]
    fn test_chinese_citation_marker_cutoff() {
        // [J] marker should terminate the title
        let title = "Some great research title[J]. Journal Name, 2024";
        let cleaned = clean_title(title, false);
        assert!(
            !cleaned.contains("[J]"),
            "Chinese citation marker [J] should be removed: {}",
            cleaned,
        );
        assert!(
            cleaned.contains("great research title"),
            "Title content should be preserved: {}",
            cleaned,
        );
    }

    #[test]
    fn test_venue_leak_abbreviated_journal_after_question() {
        // "? IEEE Trans. Aut. Contr. 53" should not leak into title
        let title = "Can machines think? IEEE Trans. Aut. Contr. 53 (2008), no. 4";
        let cleaned = clean_title(title, false);
        assert!(
            !cleaned.contains("IEEE"),
            "IEEE journal should not leak into title: {}",
            cleaned,
        );
        assert!(
            cleaned.contains("Can machines think"),
            "Title content should be preserved: {}",
            cleaned,
        );
    }

    #[test]
    fn test_venue_leak_journal_vol_after_question() {
        // "? Automatica 34(5)" should be truncated at ?
        let title = "What is consciousness? Automatica 34(5): 123-456";
        let cleaned = clean_title(title, false);
        assert!(
            !cleaned.contains("Automatica"),
            "Should not contain journal name after ?: {}",
            cleaned,
        );
    }

    #[test]
    fn test_two_word_quoted_title() {
        let ref_text = r#"A. van der Schaft, "Cyclo-dissipativity revisited," IEEE Transactions on Automatic Control, vol. 66, no. 6, pp. 2925-2931, 2021."#;
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(from_quotes, "Should detect quoted title");
        assert!(
            title.contains("Cyclo-dissipativity"),
            "Should extract 2-word quoted title: {}",
            title,
        );
    }

    #[test]
    fn test_reference_prefix_stripping() {
        // [N] prefix should be stripped
        let ref_text =
            r#"[42] Jones, A. "A comprehensive survey on neural networks," Proc. AAAI, 2023."#;
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("comprehensive survey"),
            "Should extract title after stripping [N] prefix: {}",
            title,
        );

        // N. prefix should be stripped
        let ref_text2 = r#"1. Smith, J. "Deep learning for NLP applications," Nature, 2024."#;
        let (title2, _) = extract_title_from_reference(ref_text2);
        assert!(
            title2.contains("Deep learning"),
            "Should extract title after stripping N. prefix: {}",
            title2,
        );
    }

    #[test]
    fn test_format5_skip_chinese_allcaps() {
        // Western ALL CAPS should NOT match Chinese pattern
        let ref_text_western =
            "SMITH, J., AND JONES, A. A novel approach to detection. In Proceedings of AAAI.";
        let (title, _) = extract_title_from_reference(ref_text_western);
        assert!(
            !title.is_empty(),
            "Western ALL CAPS should still extract a title: {}",
            title,
        );
    }

    // ───────────────── Tests for new format extractors ─────────────────

    #[test]
    fn test_bracket_code_format() {
        let ref_text = "[ACGH20] Gorjan Alagic, Andrew M. Childs, Alex B. Grilo, and Shih-Han Hung. Noninteractive classical verification of quantum computation. In CRYPTO 2020.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("Noninteractive classical verification"),
            "Should extract title from bracket code format: {}",
            title,
        );
    }

    #[test]
    fn test_bracket_code_format_ccy20() {
        let ref_text = "[CCY20] Nai-Hui Chia, Kai-Min Chung, and Takashi Yamakawa. Classical verification of quantum computations with efficient verifier. In Theory of Cryptography Conference 2020.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("Classical verification of quantum computations"),
            "Should extract title from bracket code format: {}",
            title,
        );
    }

    #[test]
    fn test_author_particles_von() {
        let ref_text = "M. Backes, S. Bugiel, O. Schranz, P. von Styp-Rekowsky, and S. Weisgerber. Artist: The android runtime instrumentation and security toolkit. In EuroS&P, 2017.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("Artist") || title.contains("android runtime"),
            "Should extract title with von particle in author: {}",
            title,
        );
    }

    #[test]
    fn test_author_particles_van_der() {
        let ref_text = "C. J. Hoofnagle, B. van der Sloot, and F. Z. Borgesius. The european union general data protection regulation: what it is and what it means. Information & Communications Technology Law, 28(1), 2019.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("european union general data protection"),
            "Should extract title with van der particle in author: {}",
            title,
        );
    }

    #[test]
    fn test_author_particles_le() {
        let ref_text = "K. Allix, T. F. Bissyand\u{00B4}e, J. Klein, and Y. Le Traon. Androzoo: Collecting millions of android apps for the research community. In MSR, 2016.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("Androzoo") || title.contains("Collecting millions"),
            "Should extract title with Le particle in author: {}",
            title,
        );
    }

    #[test]
    fn test_author_particles_fifty_ways() {
        let ref_text = "J. Reardon, \u{00B4}A. Feal, P. Wijesekera, A. E. B. On, N. Vallina-Rodriguez, and S. Egelman. 50 ways to leak your data: An exploration of apps' circumvention of the android permissions system. In USENIX Security, 2019.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("50 ways to leak"),
            "Should extract title starting with number: {}",
            title,
        );
    }

    #[test]
    fn test_direct_in_venue() {
        let ref_text = "Beating the random assignment on constraint satisfaction problems of bounded degree. In Naveen Garg, Klaus Jansen, Anup Rao, editors, Approximation.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("Beating the random assignment"),
            "Should extract title from direct 'Title. In Venue' format: {}",
            title,
        );
    }

    #[test]
    fn test_editor_list_cleaning() {
        let title = "Beating the random assignment on constraint satisfaction problems. In Naveen Garg, Klaus Jansen, Anup Rao, and Jos\u{00E9} Rolim, editors, Approximation";
        let cleaned = clean_title(title, false);
        assert!(
            !cleaned.contains("editors"),
            "Editor list should be removed from title: {}",
            cleaned,
        );
        assert!(
            cleaned.contains("Beating the random assignment"),
            "Title content should be preserved: {}",
            cleaned,
        );
    }

    #[test]
    fn test_editor_list_simple() {
        let title =
            "A great paper title. In John Smith and Jane Doe, editors, Proceedings of Something";
        let cleaned = clean_title(title, false);
        assert!(
            !cleaned.contains("editors"),
            "Editor list should be removed: {}",
            cleaned,
        );
        assert!(
            cleaned.contains("great paper title"),
            "Title content should be preserved: {}",
            cleaned,
        );
    }

    #[test]
    fn test_springer_lncs_bloom() {
        // Enhanced Springer/LNCS with journal metadata detection
        let ref_text = "Bloom, B.S.: The 2 sigma problem: The search for methods of group instruction as effective as one-to-one tutoring. Educational Researcher 13(6), 4\u{2013}16 (1984)";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("2 sigma problem"),
            "Should extract title from Springer format: {}",
            title,
        );
        assert!(
            !title.contains("Educational Researcher"),
            "Should not include journal name: {}",
            title,
        );
    }

    #[test]
    fn test_springer_lncs_multi_initial() {
        // Multi-initial author like "C.P.:" or "B.S.:"
        let ref_text = "Schnorr, C.P.: Efficient signature generation by smart cards. Journal of cryptology 4(3), 161\u{2013}174 (1991)";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("Efficient signature generation"),
            "Should extract title with multi-initial author: {}",
            title,
        );
    }

    #[test]
    fn test_is_journal_metadata_detection() {
        // These should be detected as journal metadata
        assert!(is_journal_metadata(
            "Educational Researcher 13(6), 4\u{2013}16 (1984)"
        ));
        assert!(is_journal_metadata(
            "Nature 299(5886), 802\u{2013}803 (1982)"
        ));
        assert!(is_journal_metadata(
            "In: Proceedings of the 8th ACM Conference"
        ));
        assert!(is_journal_metadata("13(6), 4\u{2013}16 (1984)"));

        // These should NOT be detected as metadata
        assert!(!is_journal_metadata(
            "The 2 sigma problem: The search for methods"
        ));
        assert!(!is_journal_metadata(
            "Knowledge tracing: Modeling the acquisition"
        ));
        assert!(!is_journal_metadata(
            "A survey on deep learning for cybersecurity"
        ));
    }

    // ───────────────── NeurIPS validation fix tests ─────────────────

    #[test]
    fn test_venue_after_punctuation_conference() {
        // FIX 1: Conference/workshop venue after ?/! should be truncated
        let title = "Can transformers sort? International Conference on AI and Statistics";
        let cleaned = clean_title(title, false);
        assert_eq!(cleaned, "Can transformers sort?");
    }

    #[test]
    fn test_venue_after_punctuation_association() {
        let title = "Can unconfident llm annotations be used? Nations of the Americas Chapter of the Association for Computational Linguistics";
        let cleaned = clean_title(title, false);
        assert_eq!(cleaned, "Can unconfident llm annotations be used?");
    }

    #[test]
    fn test_venue_after_punctuation_year_conference() {
        let title = "Is this the answer! The 2023 Conference on Empirical Methods";
        let cleaned = clean_title(title, false);
        assert_eq!(cleaned, "Is this the answer!");
    }

    #[test]
    fn test_venue_after_punctuation_no_venue() {
        // Should NOT be truncated — no venue keyword after ?
        let title = "Can LLMs keep a secret? Testing privacy implications";
        let cleaned = clean_title(title, true); // from_quotes to skip sentence truncation
        assert!(
            cleaned.contains("Testing privacy"),
            "Should not truncate when no venue follows: {}",
            cleaned,
        );
    }

    #[test]
    fn test_venue_only_rejection() {
        // FIX 2: Venue-only titles should be rejected (empty string returned)
        assert_eq!(
            clean_title("SIAM Journal on Scientific Computing", false),
            ""
        );
        assert_eq!(
            clean_title("IEEE Transactions on Pattern Analysis", false),
            ""
        );
        assert_eq!(
            clean_title("Journal of Machine Learning Research", false),
            ""
        );
        assert_eq!(
            clean_title("Proceedings of the International Conference", false),
            ""
        );
        assert_eq!(
            clean_title("Advances in Neural Information Processing Systems", false),
            ""
        );
    }

    #[test]
    fn test_venue_only_valid_titles_not_rejected() {
        // Valid titles should NOT be rejected
        assert_ne!(
            clean_title("A Survey of Machine Learning Techniques", false),
            ""
        );
        assert_ne!(clean_title("Attention Is All You Need", false), "");
    }

    #[test]
    fn test_author_initials_list_rejection() {
        // FIX 3: Author initials lists should be rejected
        assert_eq!(
            clean_title(
                "AL, Andrew Ahn, Nic Becker, Stephanie Carroll, Nico Christie",
                false
            ),
            ""
        );
        assert_eq!(
            clean_title("AB, John Smith, Jane Doe, Bob Wilson", false),
            ""
        );
    }

    #[test]
    fn test_author_initials_valid_titles_not_rejected() {
        // Titles starting with acronyms should NOT be rejected
        assert_ne!(
            clean_title("AI, Machine Learning, and Deep Networks: A Survey", false),
            ""
        );
    }

    #[test]
    fn test_non_reference_content_rejection() {
        // FIX 4: NeurIPS checklists and acknowledgments should be rejected
        assert_eq!(
            clean_title(
                "\u{2022} The answer NA means that the paper has no limitation",
                false
            ),
            ""
        );
        assert_eq!(
            clean_title("- Released models that have a high risk for misuse", false),
            ""
        );
        assert_eq!(
            clean_title(
                "We gratefully acknowledge the support of the OpenReview sponsors",
                false
            ),
            ""
        );
    }

    #[test]
    fn test_non_reference_valid_titles_not_rejected() {
        // Valid titles should NOT be rejected
        assert_ne!(clean_title("The Answer to Everything: A Survey", false), "");
    }

    #[test]
    fn test_title_max_length_rejection() {
        // FIX 5: Titles >300 chars should be rejected
        let long_title = "A".repeat(301);
        assert_eq!(clean_title(&long_title, false), "");

        let ok_title = "A".repeat(250);
        assert_ne!(clean_title(&ok_title, false), "");
    }

    #[test]
    fn test_is_venue_only_detection() {
        assert!(is_venue_only("SIAM Journal on Scientific Computing"));
        assert!(is_venue_only("IEEE Transactions on Pattern Analysis"));
        assert!(is_venue_only("ACM Journal on Computing Surveys"));
        assert!(is_venue_only("Journal of Machine Learning Research"));
        assert!(is_venue_only("Proceedings of the International Conference"));
        assert!(is_venue_only(
            "Advances in Neural Information Processing Systems"
        ));

        assert!(!is_venue_only("A Survey of Machine Learning Techniques"));
        assert!(!is_venue_only("Attention Is All You Need"));
        assert!(!is_venue_only("Neural Networks for Image Recognition"));
    }

    #[test]
    fn test_nested_quotes_ieee_what_if() {
        // Issue #65: nested quotes in IEEE title
        let ref_text = r#"S. Chaudhuri and V. Narasayya, "Autoadmin "what-if" index analysis utility," ACM SIGMOD Record, vol. 27, no. 2, pp. 367-378, 1998."#;
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(from_quotes, "Should detect quoted title");
        assert!(
            title.contains("Autoadmin")
                && title.contains("what-if")
                && title.contains("index analysis"),
            "Should extract full title including nested quotes: {}",
            title,
        );
    }

    #[test]
    fn test_inner_quotes_acm_proof_carrying() {
        // Issue #65: inner quotes should not be mistaken for title delimiters
        let ref_text = r#"Jacopo Tagliabue and Ciro Greco. 2025. Safe, Untrusted, "Proof-Carrying" AI Agents: toward the agentic lakehouse."#;
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("Safe, Untrusted"),
            "Should include text before inner quotes in ACM format: {}",
            title,
        );
    }

    #[test]
    fn test_author_particles_de_oliveira() {
        // Issue #65: multi-particle author names like "de Oliveira Filho"
        let ref_text = r#"P. R. X. do Carmo, E. Freitas, A. T. de Oliveira Filho, and D. F. H. Sadok, "A round-trip time and virtualization dataset," In Proceedings of ACM Conference, 2020."#;
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(from_quotes, "Should detect quoted title");
        assert!(
            title.contains("round-trip time") && title.contains("virtualization"),
            "Should extract title despite multi-particle author names: {}",
            title,
        );
    }

    // ───────────────── Edge case fixes ─────────────────

    #[test]
    fn test_asn1_period_not_sentence_boundary() {
        // "ASN.1" should not be treated as a sentence boundary
        let title = "ASN.1-based Fuzzing of Radio Resource Control Protocol for 4G and 5G";
        let cleaned = clean_title(title, false);
        assert!(
            cleaned.contains("ASN.1-based Fuzzing"),
            "ASN.1 period should not truncate title: {}",
            cleaned,
        );
    }

    #[test]
    fn test_berserker_asn1_full_reference() {
        // Full reference with ASN.1 in the title
        let ref_text = r#"H. Kim, J. Park, and S. Lee, "Berserker: ASN.1-based Fuzzing of Radio Resource Control Protocol for 4G and 5G," in Proc. IEEE Security, 2023."#;
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(from_quotes, "Should detect quoted title");
        let cleaned = clean_title(&title, from_quotes);
        assert!(
            cleaned.contains("ASN.1-based"),
            "Title should preserve ASN.1: {}",
            cleaned,
        );
        assert!(
            cleaned.contains("4G and 5G"),
            "Title should contain full text: {}",
            cleaned,
        );
    }

    #[test]
    fn test_over_the_air_hyphenation_in_title() {
        // "Over-The-Air" with line break should preserve hyphens
        let ref_text = "B. Stone, A. Reed, and C. Hall. BaseBridge: Bridging the Gap between Emulation and Over-\nThe-Air Testing for Cellular Baseband Firmware. In USENIX Security, 2024.";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            cleaned.contains("Over-The-Air"),
            "Should preserve Over-The-Air compound: {}",
            cleaned,
        );
    }

    #[test]
    fn test_pacmpl_after_question_mark() {
        // "PACMPL, 2019" after question mark should not leak into title
        let ref_text = "Micha\u{00EB}l Marcozzi, Qiyi Tang, Alastair F Donaldson, and Cristian Cadar. Compiler fuzzing: How much does it matter? PACMPL, 2019";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            !cleaned.contains("PACMPL"),
            "PACMPL venue should not leak into title: {}",
            cleaned,
        );
        assert!(
            cleaned.contains("How much does it matter?"),
            "Title should end with question mark: {}",
            cleaned,
        );
    }

    #[test]
    fn test_iacr_eprint_after_exclamation() {
        // Issue #164: "IACR Cryptology ePrint Archive" after ! should not leak into title
        let ref_text = "Aljosha Judmayer, Nicholas Stifter, Philipp Schindler, and Edgar R. Weippl. Estimating (miner) extractable value is hard, let's go shopping! IACR Cryptology ePrint Archive, 2021.";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            !cleaned.contains("IACR"),
            "IACR venue should not leak into title: {}",
            cleaned,
        );
        assert!(
            cleaned.contains("let's go shopping!"),
            "Title should end with exclamation mark: {}",
            cleaned,
        );
    }

    #[test]
    fn test_iacr_preserved_in_title_body() {
        // IACR should only be stripped when it's a venue suffix after punctuation,
        // not when it's legitimately part of the title content
        let title = "Understanding IACR Standards for Cryptographic Protocols";
        let cleaned = clean_title(title, false);
        assert!(
            cleaned.contains("IACR"),
            "IACR in title body should be preserved: {}",
            cleaned,
        );
    }

    #[test]
    fn test_version_number_period_not_sentence_boundary() {
        // Version numbers like "2.0" should not be treated as sentence boundaries
        let title = "Web 2.0 Technologies for Social Computing";
        let cleaned = clean_title(title, false);
        assert!(
            cleaned.contains("Web 2.0 Technologies"),
            "Period in 2.0 should not truncate title: {}",
            cleaned,
        );
    }

    #[test]
    fn test_book_citation_format() {
        // Issue #165: Book citation with comma after authors
        let ref_text = "R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction. MIT press, 2018.";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            !cleaned.contains("Barto"),
            "Author name should not be in title: {}",
            cleaned
        );
        assert!(
            cleaned.contains("Reinforcement learning"),
            "Title should contain main content: {}",
            cleaned
        );
    }

    #[test]
    fn test_acm_non_numeric_issue() {
        // Issue #147: Non-numeric issue numbers (e.g., "Issue CSCW") cause title misparsing
        let ref_text = "Josephine Lau, Benjamin Zimmerman, and Florian Schaub. 2018. Alexa, Are You Listening?: Privacy Perceptions, Concerns and Privacy-seeking Behaviors with Smart Speakers. Proceedings of the ACM on Human-Computer Interaction 2 (2018). Issue CSCW.";
        let (title, _) = extract_title_from_reference(ref_text);
        let cleaned = clean_title(&title, false);
        assert!(
            cleaned.contains("Alexa"),
            "Title should contain 'Alexa': {}",
            cleaned
        );
        assert!(
            !cleaned.contains("Issue CSCW"),
            "Title should not be 'Issue CSCW': {}",
            cleaned
        );
    }

    #[test]
    fn test_the_journal_after_question_mark() {
        // "The American Economic Review" after ? should not leak into title
        let title = "Will affirmative-action policies eliminate negative stereotypes? The American Economic Review";
        let cleaned = clean_title(title, false);
        assert!(
            !cleaned.contains("American Economic"),
            "Journal name should not leak into title: {}",
            cleaned
        );
        assert!(
            cleaned.contains("eliminate negative stereotypes?"),
            "Title should end with question mark: {}",
            cleaned
        );
    }

    #[test]
    fn test_trailing_month_year() {
        // ", 5 2019" or ", 3 2023" at end should be stripped
        let title1 = "The privilege, bias, and diversity challenges in college admissions, 5 2019";
        let cleaned1 = clean_title(title1, false);
        assert!(
            !cleaned1.contains("2019"),
            "Month/year should be stripped: {}",
            cleaned1
        );
        assert!(
            cleaned1.contains("college admissions"),
            "Title content should be preserved: {}",
            cleaned1
        );

        let title2 = "The enduring grip of the gender pay gap, 3 2023";
        let cleaned2 = clean_title(title2, false);
        assert!(
            !cleaned2.contains("2023"),
            "Month/year should be stripped: {}",
            cleaned2
        );
        assert!(
            cleaned2.contains("gender pay gap"),
            "Title content should be preserved: {}",
            cleaned2
        );
    }

    // =========================================================================
    // Tests for arxiv ground-truth comparison issues (2025-02-19)
    // =========================================================================

    #[test]
    fn test_venue_bleeding_after_quoted_title() {
        // Issue: Title includes venue after closing quote
        // Raw: R. Abu-Salma, J. Choy, A. Frik, and J. Bernd, ""They didn't buy their smart TV...devices," ACM Transactions...
        let ref_text = r#"R. Abu-Salma, J. Choy, A. Frik, and J. Bernd, ""They didn't buy their smart TV to watch me with the kids": Comparing nannies' and parents' privacy threat models for smart home devices," ACM Transactions on Computer-Human Interaction, vol. 31, no. 2, pp. 1-42, 2024."#;
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(from_quotes, "Should detect quoted title");
        assert!(
            !title.contains("ACM Transactions"),
            "Venue should not bleed into title: {}",
            title
        );
        assert!(
            title.contains("smart home devices"),
            "Title should contain the actual content: {}",
            title
        );
    }

    #[test]
    fn test_venue_bleeding_with_inner_colon() {
        // Titles with inner colons followed by venue
        let ref_text = r#"J. Smith and A. Jones, "Understanding AI: A comprehensive guide to machine learning," IEEE Transactions on Neural Networks, vol. 35, 2024."#;
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            !title.contains("IEEE Transactions"),
            "Venue should not bleed into title: {}",
            title
        );
        assert!(
            title.contains("machine learning"),
            "Full title should be extracted: {}",
            title
        );
    }

    #[test]
    fn test_arxiv_preprint_not_title() {
        // Issue: Title extraction fails and "arXiv preprint" becomes the title
        // Raw: Bowe, S., Maller, M., et al.: Halo: Recursive proof composition without a trusted setup. arXiv preprint arXiv:2019.xxxxx, 2019.
        let ref_text = "Bowe, S., Maller, M., et al.: Halo: Recursive proof composition without a trusted setup. arXiv preprint arXiv:2019.07497, 2019.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.to_lowercase() != "arxiv preprint",
            "Title should not be just 'arXiv preprint': {}",
            title
        );
        assert!(
            title.contains("Halo") || title.contains("Recursive proof"),
            "Should extract actual title: {}",
            title
        );
    }

    #[test]
    fn test_arxiv_preprint_suffix_stripped() {
        // arXiv preprint suffix should be stripped from titles
        let ref_text = "Yi, J., Xie, Y., Zhu, B.: Benchmarking large language models for security analysis. arXiv preprint arXiv:2305.12345, 2023.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            !title.to_lowercase().contains("arxiv preprint"),
            "arXiv preprint should be stripped: {}",
            title
        );
    }

    #[test]
    fn test_title_not_in_proceedings() {
        // Issue: "In Proceedings..." becomes the title instead of the actual title
        // Raw: J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and A. Y. Ng. Multimodal deep learning. In Proceedings of the 28th International Conference on Machine Learning, 2011.
        let ref_text = "J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and A. Y. Ng. Multimodal deep learning. In Proceedings of the 28th International Conference on Machine Learning, 2011.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            !title.starts_with("In Proc"),
            "Title should not start with 'In Proceedings': {}",
            title
        );
        assert!(
            title.contains("Multimodal") || title.contains("deep learning"),
            "Should extract actual title: {}",
            title
        );
    }

    #[test]
    fn test_title_not_in_proceedings_variant() {
        // Another variant where venue becomes title
        let ref_text = "A. Brown, A. Tuor, B. Hutchinson, and N. Mez. Recurrent neural network attention mechanisms for interpretable system log anomaly detection. In Proceedings of the First Workshop on Machine Learning for Computing Systems, 2018.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            !title.starts_with("In Proc"),
            "Title should not start with 'In Proceedings': {}",
            title
        );
        assert!(
            title.contains("Recurrent") || title.contains("anomaly detection"),
            "Should extract actual title: {}",
            title
        );
    }

    #[test]
    fn test_code_snippet_rejected_as_title() {
        // Issue: Assembly code extracted as title
        // Raw: asm volatile("rep; movsb;" : "=S"(junk_a), "=D"(junk_b) : "c"(nbytes)...
        let code_title =
            r#"rep; movsb;: "=S"(junk_a), "=D"(junk_b) : "c"(nbytes), "S"(src), "D"(dst)"#;
        let cleaned = clean_title(code_title, false);
        assert_eq!(
            cleaned, "",
            "Code snippets should be rejected as titles: {}",
            cleaned
        );
    }

    #[test]
    fn test_code_snippet_with_asm() {
        // More code patterns that should be rejected
        let code1 = r#"asm volatile("rep; movsb;" : "=S"(junk_a))"#;
        let cleaned1 = clean_title(code1, false);
        assert_eq!(cleaned1, "", "ASM code should be rejected");

        let code2 = "mov eax, ebx; push ecx; call func";
        let cleaned2 = clean_title(code2, false);
        assert_eq!(cleaned2, "", "Assembly instructions should be rejected");
    }

    #[test]
    fn test_springer_nature_with_arxiv_suffix() {
        // Springer/Nature format with arXiv suffix that shouldn't bleed
        let ref_text = "Kampourakis, V., Smiliotopoulos, C., Gkioulos, V., Katsikas, S.: In numeris veritas: An empirical study of security vulnerabilities. arXiv preprint arXiv:2301.12345, 2023.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            !title.to_lowercase().contains("arxiv"),
            "arXiv should not be in title: {}",
            title
        );
        assert!(
            title.contains("numeris") || title.contains("empirical"),
            "Should extract actual title: {}",
            title
        );
    }

    #[test]
    fn test_acm_no_date_marker() {
        // ACM format with [n. d.] (no date) marker
        let ref_text = "Abhiram Kothapalli, Srinath T. V. Setty, and Ioanna Tzialla. [n. d.]. Nova: Recursive Zero-Knowledge Arguments from Folding Schemes. In Advances in Cryptology.";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.contains("Nova") || title.contains("Recursive"),
            "Should extract title after [n. d.] marker: {}",
            title
        );
        assert!(
            !title.contains("[n"),
            "Title should not start with [n: {}",
            title
        );
    }

    #[test]
    fn test_acm_year_first_format() {
        // ACM year-first format: Authors. Year. Title. Venue.
        // extract_title_from_reference returns raw title, clean_title strips the year
        let ref_text = "Y. Zhang, D. Genkin, J. Katz, D. Papadopoulos, and C. Papamanthou. 2017. vSQL: Verifying Arbitrary SQL Queries over Dynamic Outsourced Databases. In 2017 IEEE Symposium.";
        let (raw_title, from_quotes) = extract_title_from_reference(ref_text);
        // Raw extraction may include the year
        assert!(
            raw_title.contains("vSQL"),
            "Raw title should contain the actual title: {}",
            raw_title
        );
        // After cleaning, the year should be stripped
        let cleaned = clean_title(&raw_title, from_quotes);
        assert!(
            !cleaned.starts_with("2017"),
            "Cleaned title should not start with year: {}",
            cleaned
        );
        assert!(
            cleaned.contains("vSQL"),
            "Cleaned title should preserve content: {}",
            cleaned
        );
    }

    #[test]
    fn test_arxiv_preprint_format() {
        // arXiv preprint format: Authors. Title. Year. arXiv: ID
        let ref_text = "Michael Rodler, David Paaßen, Wenting Li, and Lucas Davi. EF/CF: High Performance Smart Contract Fuzzing for Exploit Generation. 2023. arXiv: 2304.06341 [cs.CR].";
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            !title.to_lowercase().contains("arxiv"),
            "Title should not contain arXiv: {}",
            title
        );
        assert!(
            title.contains("EF/CF") || title.contains("High Performance"),
            "Should extract actual title: {}",
            title
        );
    }

    #[test]
    fn test_clean_title_strips_leading_year() {
        // Leading year should be stripped from ACM-style titles
        let title = "2017. vSQL: Verifying Arbitrary SQL Queries";
        let cleaned = clean_title(title, false);
        assert!(
            !cleaned.starts_with("2017"),
            "Leading year should be stripped: {}",
            cleaned
        );
        assert!(
            cleaned.contains("vSQL"),
            "Title content should be preserved: {}",
            cleaned
        );
    }

    #[test]
    fn test_clean_title_rejects_arxiv_id() {
        // arXiv IDs should be rejected as titles
        let title = "arXiv: 2304.06341 [cs.CR]";
        let cleaned = clean_title(title, false);
        assert_eq!(cleaned, "", "arXiv ID should be rejected as title");
    }

    #[test]
    fn test_clean_title_rejects_doi_url() {
        // DOI URLs should be rejected as titles
        let title = "https://doi.org/10.1109/SP.2017.123";
        let cleaned = clean_title(title, false);
        assert_eq!(cleaned, "", "DOI URL should be rejected as title");
    }
}

#[cfg(test)]
mod quote_fix_tests {
    use super::*;

    #[test]
    fn test_lowercase_continuation_after_quote() {
        // Quote at start, lowercase continuation (no colon/dash)
        let ref_text = r#"John Smith. "Be nice or leave me alone" examining social norms in online communities. In CHI, 2023."#;
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(from_quotes, "Should be from quotes");
        assert!(
            title.to_lowercase().contains("examining") || title.to_lowercase().contains("social"),
            "Title should include text after quotes: {}",
            title
        );
    }

    #[test]
    fn test_middle_quote_skipped() {
        // Quote in middle of title - should be handled by other extractors
        let ref_text =
            r#"John Smith. A Study of "Something Important" in Modern Systems. In Conf, 2024."#;
        let (title, _) = extract_title_from_reference(ref_text);
        assert!(
            title.to_lowercase().contains("study") || title.to_lowercase().contains("modern"),
            "Title should include text around quotes: {}",
            title
        );
    }

    #[test]
    fn test_colon_subtitle_still_works() {
        // Quote + colon should still work as before
        let ref_text = r#"Bob Wilson. "Do Anything Now": Characterizing jailbreak prompts on LLMs. In CCS, 2023."#;
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(from_quotes, "Should be from quotes");
        assert!(
            title.to_lowercase().contains("characterizing"),
            "Title should include subtitle after colon: {}",
            title
        );
    }

    #[test]
    fn test_uppercase_subtitle_still_works() {
        // Quote + uppercase should still work as before
        let ref_text = r#"Alice Brown. "Why Should I Trust You?" Explaining the predictions of any classifier. In KDD, 2016."#;
        let (title, from_quotes) = extract_title_from_reference(ref_text);
        assert!(from_quotes, "Should be from quotes");
        assert!(
            title.to_lowercase().contains("explaining"),
            "Title should include subtitle after uppercase: {}",
            title
        );
    }
}

#[test]
fn test_do_anything_now_from_pdf() {
    let ref_text = r#"Xinyue Shen et al. "do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models. In CCS, 2023."#;
    let (title, from_quotes) = extract_title_from_reference(ref_text);
    println!("Extracted title: {}", title);
    println!("From quotes: {}", from_quotes);
    // Should include the subtitle
    assert!(
        title.to_lowercase().contains("characterizing"),
        "Title should include subtitle: {}",
        title
    );
}

#[test]
fn test_comments_on_possibilistic() {
    let ref_text = r#"Mauro Barni, Vito Cappellini, and Alessandro Mecocci. 1996. Comments on "a possibilistic approach to clustering". IEEE Trans. Fuzzy Syst., 4(3):393–396"#;
    let (title, from_quotes) = extract_title_from_reference(ref_text);
    println!("Extracted title: {}", title);
    println!("From quotes: {}", from_quotes);
    // Should include "Comments on", not just the quoted part
    assert!(
        title.to_lowercase().contains("comments"),
        "Title should include 'Comments on': {}",
        title
    );
}

#[test]
fn test_has_title_text_before_quote_harvard() {
    let before = "Biswas, A., Saha, K. and De Choudhury, M. (2025) ";
    let result = has_title_text_before_quote(before);
    println!("Before text: '{}'", before);
    println!("has_title_text_before_quote: {}", result);
    assert!(!result, "Should NOT detect author text as title text");
}

#[test]
fn test_good_proctor_or_big_brother() {
    // Title with "or" before quoted text - should extract full title
    let ref_text = r#"John Doe. Good proctor or "Big Brother"? AI Ethics and Online Exam Supervision Technologies. In Conf, 2023."#;
    let (title, _) = extract_title_from_reference(ref_text);
    println!("Extracted title: {}", title);
    assert!(
        title.to_lowercase().contains("good proctor"),
        "Title should include 'Good proctor': {}",
        title
    );
    assert!(
        title.to_lowercase().contains("big brother"),
        "Title should include 'Big Brother': {}",
        title
    );
}
